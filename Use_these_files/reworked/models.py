# -*- coding: utf-8 -*-
"""Models.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15kYm1E4ysTLnegz9wTL-j5NWikU1gAGZ
"""

import numpy as np
import pandas as pd

from abc import abstractproperty,abstractmethod,ABC
from aif360.datasets import BinaryLabelDataset
import matplotlib.pyplot as plt
import tensorflow as tf

class Machine_model(ABC):
  @abstractmethod
  def transform_data(self,numpy_data_array,ground_truth_labels,bonus_information):
    pass

  @abstractmethod
  def get_transformed_data(self):
    pass

  @abstractmethod
  def prepare_application(self,bonus_information):
    pass

  @abstractmethod
  def apply_model(self,transformed_data_array, transformed_labels, bonus_information):
    pass

  @abstractmethod
  def postprocess_predictions(self,predictions,bonus_information):
    pass

  @abstractmethod
  def __visualize(self,predictions,bonus_information):
    pass

  def apply_complete_pipeline(self,numpy_data_array,ground_truth_labels,bonus_information):
    transformed_data_array, transformed_labels, bonus_information = self.transform_data(numpy_data_array,ground_truth_labels,bonus_information)
    prepared_model,bonus_information = self.prepare_application(bonus_information)
    predictions,bonus_information = self.apply_model(prepared_model,transformed_data_array,transformed_labels,bonus_information)
    final_predictions,bonus_information = self.postprocess_predictions(predictions,bonus_information)
    return final_predictions,bonus_information

from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing
from aif360.algorithms.inprocessing.meta_fair_classifier import MetaFairClassifier
from aif360.algorithms.inprocessing.prejudice_remover import PrejudiceRemover

class AIF360_Metafair_Classifier(Machine_model):
  

  def __init__(self,numpy_data_array,ground_truth_labels,bonus_information,label_name = ["Label"],feature_names = ["AGEP","COW","SCHL","MAR","OCCP","POBP","RELP","WKHP","SEX","RAC1P"],protected_attribute_names =['RAC1P'],privileged_protected_value = [1],verbose=1):
    self.MyHelper = AIF360_Model_Helper(numpy_data_array,ground_truth_labels,bonus_information,label_name,feature_names,protected_attribute_names ,privileged_protected_value,verbose)
    self.Aif_df = self.MyHelper.set_aif_df()

  def transform_data(self,numpy_data_array=None,ground_truth_labels=None,feature_names = None,label_name=None,protected_attribute_names =None,privileged_protected_value = None,verbose=None):
    """
    Creates an AIF360 BinaryLabel dataframe of the given data/labels and sets it as a attribute of the helper class
    """
    try:
      if numpy_data_array == None:
          numpy_data_array = self.numpy_data_array
      if ground_truth_labels == None:
          ground_truth_labels = self.ground_truth_labels
      if feature_names == None:
        feature_names = self.feature_names
      if label_name == None:
        label_name = self.label_name
      if protected_attribute_names == None:
        protected_attribute_names = self.protected_attribute_names
      if privileged_protected_value == None:
        privileged_protected_value = self.privileged_protected_value
      if verbose == None:
        verbose = self.verbose
    except AttributeError as err:
      self.__print_attribute_error_message(err)
      raise err

    self.Aif_df = self.MyHelper.set_aif_df(numpy_data_array,ground_truth_labels,feature_names,label_name,protected_attribute_names,privileged_protected_value,verbose)
    return self.Aif_df

  def get_transformed_data(self): 
    return self.Aif_df

  #TODO
  def prepare_application(self,bonus_information):

    split_value= 0.7  # splits the data set into train and test data
    dataset_orig_train, dataset_orig_test = aif_dataset.split([split_value], shuffle=True,seed=seed)

    if group_non_white == False:
      privileged_groups = [{'RAC1P': 1}]
      unprivileged_groups = [{'RAC1P': 2,'RAC1P': 3,'RAC1P': 4,'RAC1P': 5,'RAC1P': 6,'RAC1P': 7,'RAC1P': 8,'RAC1P': 9}]
    if group_non_white == True:
      privileged_groups = [{'RAC1P': 1}]
      unprivileged_groups = [{'RAC1P': -1}]

    meta_fair_sr = MetaFairClassifier(sensitive_attr="RAC1P",type="sr",seed = seed)

    return prepared_model,bonus_information

  #TODO
  def apply_model(self,transformed_data_array, transformed_labels, bonus_information):

     """
      Train the model
      """
      if verbose == 0:
          deafen(meta_fair_sr.fit,list_of_all_datasets_train[cur_dataset_num])
      if verbose >0:
        print('-------------------------------------------------')
        print('Now starting training of Metafair model on dataset:' + str(name_of_datasets[cur_dataset_num]) + ' year ' + str(list_of_years[cur_dataset_num]) + ' threshold ' + str(list_of_thresholds[cur_dataset_num]) )
        print('-------------------------------------------------')
      if verbose == 1:
        deafen(meta_fair_sr.fit,list_of_all_datasets_train[cur_dataset_num])
      if verbose == 2:
        meta_fair_sr.fit(list_of_all_datasets_train[cur_dataset_num])


    
      """
      Predict the model on all datasets
      """


      for cur_test_num in range(len(list_of_all_datasets_test)):
        preds_metafair = meta_fair_sr.predict(list_of_all_datasets_test[cur_test_num])

    return predictions,bonus_information

  #TODO
  def postprocess_predictions(self,predictions,bonus_information):
    return final_predictions,bonus_information

  #TODO
  def __visualize(self,predictions,bonus_information):
    pass

class AIF360_Model_Helper():

  def __init__(self,numpy_data_array,ground_truth_labels,bonus_information,label_name = ["Label"],feature_names = ["AGEP","COW","SCHL","MAR","OCCP","POBP","RELP","WKHP","SEX","RAC1P"],protected_attribute_names =['RAC1P'],privileged_protected_value = [1],verbose=1):
    #Must be given
    self.numpy_data_array = numpy_data_array
    self.ground_truth_labels = ground_truth_labels
    self.bonus_information = bonus_information

    #Optional parameters
    self.label_name = label_name
    self.feature_names = feature_names
    self.protected_attribute_names = protected_attribute_names
    self.privileged_protected_attributes = privileged_protected_value
    self.verbose = verbose
    return

  def __print_attribute_error_message(self,err):
    """
    Used to print error messages when a certain attribute has not yet been defined
    """
    attribute_name = err.args[0].split("'")[-2:-1][0]
    print(attribute_name, 'not yet created. You can create it using set_',end='')
    print(attribute_name.replace(' ','_'),end='')
    print('.')
    return

  def __set_values_from_bonus_information(bonus_information,keywords:list,given_values:list):

    values_to_be_used = []

    for cur_ind in range(keywords):
        if given_values[cur_ind] == None:
          values_to_be_used.append(bonus_information[keywords[i]])
        else:
          values_to_be_used.append(given_values[i])

    return values_to_be_used

  def set_pandas_df(self,numpy_data_array=None,ground_truth_labels=None,feature_names=None,label_name = None):
    """
    Creates an pandas dataframe of the given data/labels and sets it as a attribute of the helper class
    """
    try:
      if feature_names ==None:
          feature_names = self.feature_names
      if numpy_data_array == None:
          numpy_data_array = self.numpy_data_array
      if ground_truth_labels == None:
          ground_truth_labels = self.ground_truth_labels
      if label_name == None:
        label_name=self.label_name
    except AttributeError as err:
      self.__print_attribute_error_message(err)
      raise err

    df_label = pd.DataFrame(ground_truth_labels,columns=label_name)
    df_data = pd.DataFrame(data = numpy_data_array, columns = feature_names)
    self.pandas_df = pd.concat([df_data,df_label],axis=1)
    return self.pandas_df

  def get_pandas_df(self):
    """
    returns the pandas dataframe attribute of the helper class
    """
    try:
      return self.pandas_df
    except AttributeError as err:
      print('Pandas Dataframe not yet created. You can create it using set_pandas_df.')
      raise err
  #Is the above a best practice??
  
  def set_aif_df(self,numpy_data_array=None,ground_truth_labels=None,feature_names = None,label_name=None,protected_attribute_names =None,privileged_protected_value = None,verbose=None):
    """
    Creates an AIF360 BinaryLabel dataframe of the given data/labels and sets it as a attribute of the helper class
    """
    try:
      if numpy_data_array == None:
          numpy_data_array = self.numpy_data_array
      if ground_truth_labels == None:
          ground_truth_labels = self.ground_truth_labels
      if feature_names == None:
        feature_names = self.feature_names
      if label_name == None:
        label_name = self.label_name
      if protected_attribute_names == None:
        protected_attribute_names = self.protected_attribute_names
      if privileged_protected_value == None:
        privileged_protected_value = self.privileged_protected_value
      if verbose == None:
        verbose = self.verbose
    except AttributeError as err:
      self.__print_attribute_error_message(err)
      raise err
    
    try:
      if verbose>0:
        print('Trying to create Pandas Dataframe.')
      pd_df_all = self.set_pandas_df(numpy_data_array=numpy_data_array,ground_truth_labels=ground_truth_labels,feature_names=feature_names,label_name = label_name)
    except AttributeError as err:
        raise err

    self.aif_df = BinaryLabelDataset(df= pd_df_all,label_names = label_name,protected_attribute_names =protected_attribute_names,privileged_protected_attributes = privileged_protected_value)
    return self.aif_df

  def get_aif_df(self):
    """
    returns the AIF360 BinaryLabel dataframe attribute of the helper class
    """
    try:
      return self.aif_df
    except AttributeError as err:
      print('AIF360 Dataframe not yet created. You can create it using set_aif_df.')
      raise err