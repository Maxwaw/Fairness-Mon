{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Grid_training_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "8Uq7yeHZWP8m",
        "KcmzKmfxWP8o",
        "Q24AxzPqWP8p",
        "qfVsZmlzWkKU",
        "fX2G2qhuBBuR",
        "L3-_TSzNtAAG",
        "4HiWH7gHWhNM",
        "9Lj9vgzOvZZX"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üïπÔ∏è **Grid Training Notebook**"
      ],
      "metadata": {
        "id": "9pHQppN4-C_C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, a training framework is developed which can train machine models on the ACIncome Task.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Furthermore, a dashboard is created which serves as an interface for the framework and allows the user to easily explore our collected metrics.\n",
        "\n",
        "The purpose of this notebook is to allow students and researchers of AI fairness to explore how changes in temporal and/or spatial context can affect the fairness and performance of a model, as measured by various metrics. Recent research has shown that the interpretation of the fairness of classification models and datasets drastically depends on such context."
      ],
      "metadata": {
        "id": "5yv2z8uW9-da"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8u5V1dQWLXh"
      },
      "source": [
        "---\n",
        "##‚öôÔ∏è Setup Grid Training V2\n",
        "\n",
        "‚¨áÔ∏è <font color='orange'>Click on the arrow below to run the setup!</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKkTCzBNWP8k"
      },
      "source": [
        "### ‚öôÔ∏è Setup Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z72ydbBNWP8l"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqCG2TXRWP8l",
        "outputId": "12155f39-c155-4fe1-ae9a-7bd13ef0e472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting folktables\n",
            "  Downloading folktables-0.0.11.tar.gz (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from folktables) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from folktables) (1.3.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from folktables) (2.23.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from folktables) (0.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->folktables) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->folktables) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->folktables) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->folktables) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->folktables) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->folktables) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->folktables) (2.10)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->folktables) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->folktables) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->folktables) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->folktables) (3.1.0)\n",
            "Building wheels for collected packages: folktables\n",
            "  Building wheel for folktables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for folktables: filename=folktables-0.0.11-py3-none-any.whl size=6779 sha256=7bed823eb8ffc8cf5a50ea48446c5cfaf453ba391aa9b257064eafede0890ecd\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/63/b8/24d3f5d2c70002c68c1fe8e78e1de20fcbcb7a2ef3f56147b7\n",
            "Successfully built folktables\n",
            "Installing collected packages: folktables\n",
            "Successfully installed folktables-0.0.11\n"
          ]
        }
      ],
      "source": [
        "#The Library that allows us to use the American Census Data and also offers the ACIncome Task\n",
        "!pip install folktables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQ_vzWRZWP8l",
        "outputId": "df613399-2746-4df6-9b2c-b723ee0787d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50 kB 2.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein) (57.4.0)\n",
            "Building wheels for collected packages: python-Levenshtein\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149874 sha256=64f922b7b96b543ac6890deed00ea997c664bb55c610240950872340f25c79ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/5f/ca/7c4367734892581bb5ff896f15027a932c551080b2abd3e00d\n",
            "Successfully built python-Levenshtein\n",
            "Installing collected packages: python-Levenshtein\n",
            "Successfully installed python-Levenshtein-0.12.2\n"
          ]
        }
      ],
      "source": [
        "#Used for error correction of user input (state list)\n",
        "!pip install python-Levenshtein"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxWWgllnWP8l",
        "outputId": "2e13e264-26b8-438b-87e4-4eb40177c059"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting kaleido\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79.9 MB 124 kB/s \n",
            "\u001b[?25hInstalling collected packages: kaleido\n",
            "Successfully installed kaleido-0.2.1\n"
          ]
        }
      ],
      "source": [
        "# needed for saving plotly plots\n",
        "!pip install kaleido"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onyGZ3tCWP8m"
      },
      "source": [
        "**Define Dataset Helper Functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Uq7yeHZWP8m"
      },
      "source": [
        "Label Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeAAmCIxWP8m"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "function that labels numpy data (The output of the get_income_data_with_track function we defined) and returns a pandas Dataframe.\n",
        "Most importantly it gives the 10 features their respective name.\n",
        "\"\"\"\n",
        "\n",
        "def label_numpy_data(data_array, labels=[\"AGEP\",\"COW\",\"SCHL\",\"MAR\",\"OCCP\",\"POBP\",\"RELP\",\"WKHP\",\"SEX\",\"RAC1P\"]):\n",
        "  df = pd.DataFrame(data = data_array, columns = labels)\n",
        "  return df\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Generate Pandas Dataframe from given inputs (of our get_income_data_with_track function). \n",
        "This will generate one huge dataframe that contains both the features and the label of the data.\n",
        "This prepares the data for the conversion to AIF360 Binary Label Datasets.\n",
        "\"\"\"\n",
        "\n",
        "def Get_Dataframe_from_all(data_array, ground_truth, labels=[\"AGEP\",\"COW\",\"SCHL\",\"MAR\",\"OCCP\",\"POBP\",\"RELP\",\"WKHP\",\"SEX\",\"RAC1P\"]):\n",
        "  df_label = pd.DataFrame(ground_truth,columns=['Label'])\n",
        "  df_data = label_numpy_data(data_array,labels = labels)\n",
        "  df = pd.concat([df_data,df_label],axis=1)\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcmzKmfxWP8o"
      },
      "source": [
        "State Strings -> State Codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKib_vYPWP8o"
      },
      "outputs": [],
      "source": [
        "from Levenshtein import distance as levenshtein_distance\n",
        "\n",
        "\"\"\"function that calculates the nearest state given an input string list (e.g. \"washintong\" would (hopefully) be mapped to \"Washington\" \"\"\"\n",
        "def calc_nearest_state(input_list):\n",
        "\n",
        "  all_states_to_compare_to = [\"Alabama\",\"Alaska\",\"Arizona\",\"Arkansas\",\"California\",\"Colorado\",\"Connecticut\",\"Delaware\",\"District of Columbia\",\"Florida\",\"Georgia\",\"Hawaii\",\"Idaho\",\"Illinois\",\"Indiana\",\"Iowa\",\"Kansas\",\"Kentucky\",\"Louisiana\",\"Maine\",\"Maryland\",\"Massachusetts\",\"Michigan\",\"Minnesota\",\"Mississippi\",\"Missouri\",\"Montana\",\"Nebraska\",\"Nevada\",\"New Hampshire\",\"New Jersey\",\"New Mexico\",\"New York\",\"North Carolina\",\"North Dakota\",\"Ohio\",\"Oklahoma\",\"Oregon\",\"Pennsylvania\",\"Rhode Island\",\"South Carolina\",\"South Dakota\",\"Tennessee\",\"Texas\",\"Utah\",\"Vermont\",\"Virginia\",\"Washington\",\"West Virginia\",\"Wisconsin\",\"Wyoming\",\"Puerto Rico\",]\n",
        "\n",
        "  output_list = input_list.copy()\n",
        "\n",
        "  for i in range(len(input_list)):\n",
        "    cur_nearest_state = None\n",
        "    cur_score = np.infty\n",
        "    for state in all_states_to_compare_to:\n",
        "      new_score = levenshtein_distance(input_list[i],state)\n",
        "      if new_score<cur_score:\n",
        "        cur_score = new_score\n",
        "        cur_nearest_state = state\n",
        "\n",
        "    output_list[i] = cur_nearest_state\n",
        "\n",
        "  return output_list\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Example:\n",
        "calc_nearest_state([\"washingon\",\"new macico\"])\n",
        "returns -> ['Washington', 'New Mexico']\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"function that returns the state abbreviatian given the full name of a state.\"\"\"\n",
        "\n",
        "\n",
        "def get_state_code(states):\n",
        "  state_code_list = []\n",
        "\n",
        "  #define dict that given state name returns the state code\n",
        "  state_name_to_code = {\n",
        "      \n",
        "      \"Alabama\" : \"AL\",\n",
        "      \"Alaska\" : \"AK\",\n",
        "      \"Arizona\" : \"AZ\",\n",
        "      \"Arkansas\" : \"AR\",\n",
        "      \"California\" : \"CA\",\n",
        "      \"Colorado\" : \"CO\",\n",
        "      \"Connecticut\" : \"CT\",\n",
        "      \"Delaware\" : \"DE\",\n",
        "      \"District of Columbia\" : \"DC\",\n",
        "      \"Florida\" : \"FL\",\n",
        "      \"Georgia\" : \"GA\",\n",
        "      \"Hawaii\" : \"HI\",\n",
        "      \"Idaho\" : \"ID\",\n",
        "      \"Illinois\" : \"IL\",\n",
        "      \"Indiana\" : \"IN\",\n",
        "      \"Iowa\" : \"IA\",\n",
        "      \"Kansas\" : \"KS\",\n",
        "      \"Kentucky\" : \"KY\",\n",
        "      \"Louisiana\" : \"LA\",\n",
        "      \"Maine\" : \"ME\",\n",
        "      \"Maryland\" : \"MD\",\n",
        "      \"Massachusetts\" : \"MA\",\n",
        "      \"Michigan\" : \"MI\",\n",
        "      \"Minnesota\" : \"MN\",\n",
        "      \"Mississippi\" : \"MS\",\n",
        "      \"Missouri\" : \"MO\",\n",
        "      \"Montana\" : \"MT\",\n",
        "      \"Nebraska\" : \"NE\",\n",
        "      \"Nevada\" : \"NV\",\n",
        "      \"New Hampshire\" : \"NH\",\n",
        "      \"New Jersey\" : \"NJ\",\n",
        "      \"New Mexico\" : \"NM\",\n",
        "      \"New York\" : \"NY\",\n",
        "      \"North Carolina\" : \"NC\",\n",
        "      \"North Dakota\" : \"ND\",\n",
        "      \"Ohio\" : \"OH\",\n",
        "      \"Oklahoma\" : \"OK\",\n",
        "      \"Oregon\" : \"OR\",\n",
        "      \"Pennsylvania\" : \"PA\",\n",
        "      \"Rhode Island\" : \"RI\",\n",
        "      \"South Carolina\" : \"SC\",\n",
        "      \"South Dakota\" : \"SD\",\n",
        "      \"Tennessee\" : \"TN\",\n",
        "      \"Texas\" : \"TX\",\n",
        "      \"Utah\" : \"UT\",\n",
        "      \"Vermont\" : \"VT\",\n",
        "      \"Virginia\" : \"VA\",\n",
        "      \"Washington\" : \"WA\",\n",
        "      \"West Virginia\" : \"WV\",\n",
        "      \"Wisconsin\" : \"WI\",\n",
        "      \"Wyoming\" : \"WY\",\n",
        "      \"Puerto Rico\" : \"PR\",\n",
        "  }\n",
        "  for state in states:\n",
        "    if len(str(state))==2:\n",
        "      state_code_list.append(state)\n",
        "    else:\n",
        "      cur_state= calc_nearest_state([state])[0]\n",
        "      state_code_list.append(state_name_to_code[cur_state])\n",
        "\n",
        "  return state_code_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0NsNbWXWP8p",
        "outputId": "1c9e7f54-591f-4d02-ee16-d469a8e4658d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AK', 'AZ', 'CA', 'CO', 'HI', 'ID', 'MT', 'NV', 'NM', 'OR', 'UT', 'WA', 'WY']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#Example:\n",
        "\n",
        "get_state_code([\"Ilaska\", \"Arizona\", \"California\", \"Colorado\", \"Hawaii\", \"Idaho\", \"Montana\", \"Nevada\", \"Naw Maxico\", \"Oregon\", \"Utah\", \"WA\", \"Wyoming\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q24AxzPqWP8p"
      },
      "source": [
        "Generate Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32SEnEEbWP8p"
      },
      "outputs": [],
      "source": [
        "\"\"\"function that gets the ACSIncome features, labels and group. While also returning a list of where each data point originated from\"\"\"\n",
        "\n",
        "from folktables import ACSDataSource, ACSIncome, BasicProblem\n",
        "\n",
        "def adult_filter(data):\n",
        "    \"\"\"Mimic the filters in place for Adult data.\n",
        "    Adult documentation notes: Extraction was done by Barry Becker from\n",
        "    the 1994 Census database. A set of reasonably clean records was extracted\n",
        "    using the following conditions:\n",
        "    ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))\n",
        "    \"\"\"\n",
        "    df = data\n",
        "    df = df[df['AGEP'] > 16]\n",
        "    df = df[df['PINCP'] > 100]\n",
        "    df = df[df['WKHP'] > 0]\n",
        "    df = df[df['PWGTP'] >= 1]\n",
        "    return df\n",
        "\n",
        "\"\"\"\n",
        "Our main function of generating data that we will use for our models.\n",
        "\n",
        "Given a list of states and years it will download the relevant data and then return the wanted dataset(features),the labels, the group (Race) of each data sample and lists that contain the origin of the data (year, state).\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def get_income_data_with_track(states,years,threshold=50000,group_non_white=False,horizon='1-Year',survey='person'):\n",
        "  \"\"\"\n",
        "  Inputs:\n",
        "  states : list of strings (states)\n",
        "\n",
        "  years : list of non-negative numbers in the range of 2014 - 2018 (years)\n",
        "\n",
        "  threshold : non-negative number\n",
        "  default value: 50000\n",
        "  The threshold used for the ACIncome task. (Every data sample (income) above the threshold belongs to class 1 and every data sample (income) below the threshold belongs to class 0)\n",
        "\n",
        "  group_non_white: Boolean\n",
        "  default value: False\n",
        "  Whether every non-white race should be relabeled as \"Non-White\" or not.\n",
        "    If False: 9 Unique Race Values (1,2,3,4,5,6,7,8,9)\n",
        "    If True:  2 Unique Race Values (-1,1)\n",
        "\n",
        "\n",
        "  horizon='1-Year'\n",
        "  Not relevant for a typical user, used as input for the folkstable library.\n",
        "\n",
        "  survey='person'\n",
        "  Not relevant for a typical user, used as input for the folkstable library.\n",
        "\n",
        "  Returns:\n",
        "  features : numpy array of arrays (the values of the features of each data sample, here 10 features)\n",
        "  labels : numpy array of numbers (The class label of the data sample, see threshold)\n",
        "  group : numpy array of numbers (The race of the data sample, see group_non_white)\n",
        "  track_list_year : list of non-negative numbers in the range of 2014-2018 (years)\n",
        "  track_list_state : list of strings (states)\n",
        "  \"\"\"\n",
        "  for i in range(len(years)):\n",
        "    years[i] = str(years[i])\n",
        "\n",
        "  features = np.zeros((0,10))\n",
        "  labels = np.zeros((0))\n",
        "  group = np.zeros((0))\n",
        "  track_list_year = []\n",
        "  track_list_state = []\n",
        "\n",
        "  states = get_state_code(states)\n",
        "\n",
        "  IncomeProblem_own = BasicProblem(\n",
        "      features=[\n",
        "          'AGEP',\n",
        "          'COW',\n",
        "          'SCHL',\n",
        "          'MAR',\n",
        "          'OCCP',\n",
        "          'POBP',\n",
        "          'RELP',\n",
        "          'WKHP',\n",
        "          'SEX',\n",
        "          'RAC1P',\n",
        "      ],\n",
        "      target='PINCP',\n",
        "      target_transform=lambda x: x > threshold,\n",
        "      group='RAC1P',\n",
        "      preprocess=adult_filter,\n",
        "      postprocess=lambda x: np.nan_to_num(x, -1),\n",
        "    )\n",
        "\n",
        "  for year in years:\n",
        "    for state in states:\n",
        "      data_source = ACSDataSource(survey_year=year, horizon=horizon, survey=survey)\n",
        "      orig_data = data_source.get_data(states=[state], download=True)\n",
        "      orig_features, orig_labels, orig_group = IncomeProblem_own.df_to_numpy(orig_data)\n",
        "\n",
        "      if group_non_white==True:\n",
        "        #1 stays 1 and everything else becomes -1\n",
        "        orig_features[:,9] = 2*(orig_features[:,9]==1) -1\n",
        "        orig_group = 2*orig_group[orig_group==1] -1\n",
        "\n",
        "      features = np.concatenate((features, orig_features))\n",
        "      labels = np.concatenate((labels, orig_labels))\n",
        "      group = np.concatenate((group, orig_group))\n",
        "\n",
        "      for i in range(len(orig_group)):\n",
        "        track_list_year.append(int(year))\n",
        "        track_list_state.append(state)\n",
        "\n",
        "\n",
        "  return features,labels,group,track_list_year,track_list_state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfVsZmlzWkKU"
      },
      "source": [
        "### ‚öôÔ∏è Setup Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wOpVf_DWkKV",
        "outputId": "cd84148a-dd0c-45f7-801c-10ab5e6ef1e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting aif360\n",
            "  Downloading aif360-0.4.0-py3-none-any.whl (175 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 175 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from aif360) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.0.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.3.5)\n",
            "Collecting tempeh\n",
            "  Downloading tempeh-0.1.12-py3-none-any.whl (39 kB)\n",
            "Collecting scipy<1.6.0,>=1.2.0\n",
            "  Downloading scipy-1.5.4-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25.9 MB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->aif360) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->aif360) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->aif360) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->aif360) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->aif360) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->aif360) (4.1.1)\n",
            "Collecting shap\n",
            "  Downloading shap-0.41.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (569 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 569 kB 47.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tempeh->aif360) (2.23.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from tempeh->aif360) (3.6.4)\n",
            "Collecting memory-profiler\n",
            "  Downloading memory_profiler-0.60.0.tar.gz (38 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory-profiler->tempeh->aif360) (5.4.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (57.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (1.11.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (8.13.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (1.4.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (22.1.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (0.7.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360) (3.0.4)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360) (21.3)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360) (0.56.0)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba->shap->tempeh->aif360) (4.12.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap->tempeh->aif360) (0.39.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba->shap->tempeh->aif360) (3.8.1)\n",
            "Building wheels for collected packages: memory-profiler\n",
            "  Building wheel for memory-profiler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for memory-profiler: filename=memory_profiler-0.60.0-py3-none-any.whl size=31284 sha256=fddd05eecfaf88d1a2d9f7aff1f12f5842bea3b7c8c27208e173f9b2e39578cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/2b/fb/326e30d638c538e69a5eb0aa47f4223d979f502bbdb403950f\n",
            "Successfully built memory-profiler\n",
            "Installing collected packages: scipy, slicer, shap, memory-profiler, tempeh, aif360\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.5.4 which is incompatible.\u001b[0m\n",
            "Successfully installed aif360-0.4.0 memory-profiler-0.60.0 scipy-1.5.4 shap-0.41.0 slicer-0.0.7 tempeh-0.1.12\n"
          ]
        }
      ],
      "source": [
        "!pip install aif360"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q fairlearn"
      ],
      "metadata": {
        "id": "1gslDigpSXnN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9efe6de3-ac95-478a-f9b9-bd337df3f5b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |‚ñà‚ñâ                              | 10 kB 20.5 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñä                            | 20 kB 15.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                          | 30 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                        | 40 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                      | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                     | 61 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                   | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                 | 81 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã               | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå             | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé           | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ      | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 177 kB 5.1 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELpX5rddWkKW"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "# Load all necessary packages\n",
        "import sys\n",
        "sys.path.append(\"../\")\n",
        "from aif360.datasets import BinaryLabelDataset\n",
        "#from aif360.datasets import AdultDataset, GermanDataset, CompasDataset\n",
        "# from aif360.metrics import BinaryLabelDatasetMetric\n",
        "# from aif360.metrics import ClassificationMetric\n",
        "# from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
        "#from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult, load_preproc_data_compas, load_preproc_data_german\n",
        "#from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
        "#from aif360.algorithms.inprocessing.meta_fair_classifier import MetaFairClassifier\n",
        "#from sklearn.linear_model import LogisticRegression\n",
        "#from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
        "#from sklearn.metrics import accuracy_score\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  aif360  inprocessing models"
      ],
      "metadata": {
        "id": "lEx6Ivs4p4Va"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our focus to handle bias lies on **\"In-processing\"** algorithms which we took from the aif360 library.  \n",
        "AI Fairness 360 (aif360) is a open source library containing techniques to detect and mitigate bias in datasets and models.  \n",
        "In-processing algorithms are bias mitigation algorithms which are applied to a model during its training.  \n",
        "We took used thre In-Processing techniques from the aif360 library whiche are AversialDebiasing, MetafairClassifier and Prejudice Remover.\n",
        "For further information about the In-processing algorithms we linked the papers at the \"References\" paragraph of their description."
      ],
      "metadata": {
        "id": "x31kvVSWueWD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### AdversialDebiasing"
      ],
      "metadata": {
        "id": "mhgy8TjPtpdU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#3687bd'>class</font> **aif360.algorithms.inprocessing.AdversarialDebiasing**<font color='#3687bd'>(unprivileged_groups, privileged_groups, scope_name, sess, seed=None, adversary_loss_weight=0.1, num_epochs=50, batch_size=128, classifier_num_hidden_units=200, debias=True)</font>\n",
        "\n",
        "Adversarial debiasing is an in-processing technique that learns a classifier to maximize prediction accuracy and simultaneously reduce an adversary‚Äôs ability to determine the protected attribute from the predictions [5]. This approach leads to a fair classifier as the predictions cannot carry any group discrimination information that the adversary can exploit.  \n",
        "\n",
        "**Parameters:**\n",
        "*   **unprivileged_groups** (<font color='#ab74c1'>tuple</font>) ‚Äì Representation for unprivileged groups\n",
        "*   **privileged_groups** (<font color='#ab74c1'>tuple</font>) ‚Äì Representation for privileged groups  \n",
        "*   **scope_name** (<font color='#ab74c1'>str</font>) ‚Äì scope name for the tenforflow variable\n",
        "*   **sess** (tf.Session) ‚Äì tensorflow session\n",
        "*   **seed** (<font color='#3687bd'>int</font>, optional) ‚Äì Seed to make **predict** repeatable\n",
        "*   **adversary_loss_weight** ((<font color='#3687bd'>float</font>, optional) ‚Äì Hyperparameter that chooses the strength of the adversarial loss\n",
        "*   **num_epochs** ((<font color='#3687bd'>int</font>, optional) ‚Äì Number of training epochs\n",
        "*   **batch_size** ((<font color='#3687bd'>int</font>, optional) ‚Äì Batch size\n",
        "*   **classifier_num_hidden_units** ((<font color='#3687bd'>int</font>, optional) ‚Äì Number of hidden units in the classifier model\n",
        "*   **debias** ((<font color='#3687bd'>bool</font>, optional) ‚Äì Learn a classifier with or without debiasing  \n",
        "\n",
        "**References**  \n",
        "[5]\tB. H. Zhang, B. Lemoine, and M. Mitchell, ‚ÄúMitigating Unwanted Biases with Adversarial Learning,‚Äù AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, 2018.\n",
        "\n",
        "**aif360 doc:**  \n",
        "https://aif360.readthedocs.io/en/stable/modules/generated/aif360.algorithms.inprocessing.AdversarialDebiasing.html#id2"
      ],
      "metadata": {
        "id": "eUVeV1FUuadJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing"
      ],
      "metadata": {
        "id": "SQngu-uwj4gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experience**  \n",
        "The AdversialDebiasing algorithm has the option to learn a classifier with or without debiasing by setting the debias paramete to true or false which we used to compare the results.\n",
        "We \n",
        "The run time of the model w\n",
        "(Meta fair-> ~1,5 sec pro 10k\n",
        "Adversial Debiasing -> ~15,1 Sec pro 10k\n",
        "Prejudice Remover-> ~16,6 sec pro 10k \n",
        "- data set\n",
        "- speed \n",
        "- besonderheite"
      ],
      "metadata": {
        "id": "PcgzHUMtadBD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### MetafairClassifier"
      ],
      "metadata": {
        "id": "IiJpnSxmp6tm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#3687bd'>class</font> **aif360.algorithms.inprocessing.MetaFairClassifier**<font color='#3687bd'>(tau=0.8, sensitive_attr='', type='fdr', seed=None)</font>\n",
        "\n",
        "The meta algorithm here takes the fairness metric as part of the input and returns a classifier optimized w.r.t. that fairness metric [11]. \n",
        "\n",
        "**Parameters:**\n",
        "*   **tau** (double, optional) ‚Äì Fairness penalty parameter\n",
        "*   **sensitive_attr** (<font color='#ab74c1'>str</font>, optional) ‚Äì Name of protected attribute.  \n",
        "*   **type** (<font color='#ab74c1'>str</font>, optional) ‚Äì The type of fairness metric to be used. Currently ‚Äúfdr‚Äù (false discovery rate ratio) and ‚Äúsr‚Äù (statistical rate/disparate impact) are supported. To use another type, the corresponding optimization class has to be implemented.\n",
        "*   **seed** (int, optional) ‚Äì Random seed.\n",
        "\n",
        "**References**  \n",
        "[11]\tL. E. Celis, L. Huang, V. Keswani, and N. K. Vishnoi. ‚ÄúClassification with Fairness Constraints: A Meta-Algorithm with Provable Guarantees,‚Äù 2018.\n",
        "\n",
        "\n",
        "**aif360 doc:**  \n",
        "https://aif360.readthedocs.io/en/stable/modules/generated/aif360.algorithms.inprocessing.MetaFairClassifier.html\n"
      ],
      "metadata": {
        "id": "AfJdZL2zur4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from aif360.algorithms.inprocessing.meta_fair_classifier import MetaFairClassifier"
      ],
      "metadata": {
        "id": "A2oBjqYjNaAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ist nur auf"
      ],
      "metadata": {
        "id": "XMwb5sTSazYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### PrejudiceRemover"
      ],
      "metadata": {
        "id": "lye_Tj_3p5IW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#3687bd'>class</font> **aif360.algorithms.inprocessing.PrejudiceRemover**<font color='#3687bd'>(eta=1.0, sensitive_attr='', class_attr='')</font>\n",
        "\n",
        "Prejudice remover is an in-processing technique that adds a discrimination-aware regularization term to the learning objective [6].  \n",
        "\n",
        "**Parameters:**\n",
        "*   **eta** (double, optional) ‚Äì fairness penalty parameter\n",
        "*   **sensitive_attr** (<font color='#ab74c1'>str</font>, optional) ‚Äì name of protected attribute  \n",
        "*   **class_attr** (<font color='#ab74c1'>str</font>, optional) ‚Äì label name\n",
        "\n",
        "**References**  \n",
        "[6]\tT. Kamishima, S. Akaho, H. Asoh, and J. Sakuma, ‚ÄúFairness-Aware Classifier with Prejudice Remover Regularizer,‚Äù Joint European Conference on Machine Learning and Knowledge Discovery in Databases, 2012.\n",
        "\n",
        "\n",
        "**aif360 doc:**  \n",
        "https://aif360.readthedocs.io/en/stable/modules/generated/aif360.algorithms.inprocessing.PrejudiceRemover.html\n"
      ],
      "metadata": {
        "id": "JntgrQWW0u2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from aif360.algorithms.inprocessing.prejudice_remover import PrejudiceRemover"
      ],
      "metadata": {
        "id": "tFRCGowRQQOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIDEf6DPVwX9"
      },
      "source": [
        "### ‚öôÔ∏è Setup Pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pickle is a library that allows us to generate files out of complex variables.\n",
        "\n",
        "We use it to save our train datasets and the predictions of the model."
      ],
      "metadata": {
        "id": "KHBy1ZkeJEZk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDxKJ0j2V8Pi"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚öôÔ∏è Setup Metrics"
      ],
      "metadata": {
        "id": "fX2G2qhuBBuR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we setup the metrics that will be evaluated for each model. \n",
        "<br></br>\n",
        "For that, we use all the metrics of `aif360.metrics.ClassificationMetric` ([docs](https://aif360.readthedocs.io/en/stable/modules/generated/aif360.metrics.ClassificationMetric.html)), which is a mix of performance and fairness related metrics. Additionally, we compute the ABROCA (actually just BROCA, since we do not take the absolute value to retain information about the favored group). Finally, we store all metrics in a csv-file, which will be used in our `metrics-visualization.ipynb` notebook.\n",
        "\n",
        "ABROCA is a powerful fairness metric used in predictive modeling [proposed in 2019 by Gardner et. al](https://dl.acm.org/doi/10.1145/3303772.3303791), which is one of the main metrics we will use to assess model fairness throughout this project. It is formally defined as:\n",
        "\n",
        "![Screenshot 2022-08-08 204927.png](data:image/png;base64,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)\n",
        "\n",
        "Another important metric for assessing fairness is Disparate Impact, which is defined in the `aif360` library. The formula for disparate impact is the following:\n",
        "\n",
        "![Screenshot 2022-08-08 204821.png](data:image/png;base64,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)\n",
        "\n",
        "Still, it is important that we collect all the other metrics, too, as we want to allow the users to explore the collected metrics themselves."
      ],
      "metadata": {
        "id": "FtwZa3yLvi8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# function to compute ABROCA given two datasets\n",
        "def abroca(test_dataset, pred_dataset):\n",
        "    df_test, _ = test_dataset.convert_to_dataframe()\n",
        "    df_pred, _ = pred_dataset.convert_to_dataframe()\n",
        "\n",
        "    df = pd.concat([df_test[\"Label\"], df_pred[\"Label\"], df_test[\"RAC1P\"]],\n",
        "                   axis=1,\n",
        "                   keys=[\"gt\", \"pred\", \"race\"])\n",
        "\n",
        "    return compute_abroca(df)\n",
        "\n",
        "# function to compute ABROCA given a dataframe with columns race, gt and pred\n",
        "def compute_abroca(df):\n",
        "    roc_auc_WHITE = roc_auc_score(y_true=df[df[\"race\"] == 1][\"gt\"],\n",
        "                              y_score=df[df[\"race\"] == 1][\"pred\"])\n",
        "\n",
        "    roc_auc_OTHER = roc_auc_score(y_true=df[df[\"race\"] != 1][\"gt\"],\n",
        "                              y_score=df[df[\"race\"] != 1][\"pred\"])\n",
        "\n",
        "    return roc_auc_WHITE - roc_auc_OTHER"
      ],
      "metadata": {
        "id": "qAk0bqFLxAdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from aif360.datasets import BinaryLabelDataset\n",
        "from aif360.metrics import ClassificationMetric\n",
        "\n",
        "import pickle\n",
        "import csv\n",
        "\n",
        "METRIC_NAMES = ['model_name',\n",
        "                'abroca',\n",
        "                'accuracy',\n",
        "                'average_abs_odds_difference',\n",
        "                'average_odds_difference',\n",
        "                'base_rate',\n",
        "                'between_all_groups_coefficient_of_variation',\n",
        "                'between_all_groups_generalized_entropy_index',\n",
        "                'between_all_groups_theil_index',\n",
        "                'between_group_coefficient_of_variation',\n",
        "                'between_group_generalized_entropy_index',\n",
        "                'between_group_theil_index',\n",
        "                'binary_confusion_matrix',\n",
        "                'coefficient_of_variation',\n",
        "                'consistency',\n",
        "                'difference',\n",
        "                'differential_fairness_bias_amplification',\n",
        "                'disparate_impact',\n",
        "                'equal_opportunity_difference',\n",
        "                'error_rate',\n",
        "                'error_rate_difference',\n",
        "                'error_rate_ratio',\n",
        "                'false_discovery_rate',\n",
        "                'false_discovery_rate_difference',\n",
        "                'false_discovery_rate_ratio',\n",
        "                'false_negative_rate',\n",
        "                'false_negative_rate_difference',\n",
        "                'false_negative_rate_ratio',\n",
        "                'false_omission_rate',\n",
        "                'false_omission_rate_difference',\n",
        "                'false_omission_rate_ratio',\n",
        "                'false_positive_rate',\n",
        "                'false_positive_rate_difference',\n",
        "                'false_positive_rate_ratio',\n",
        "                'generalized_binary_confusion_matrix',\n",
        "                'generalized_entropy_index',\n",
        "                'generalized_false_negative_rate',\n",
        "                'generalized_false_positive_rate',\n",
        "                'generalized_true_negative_rate',\n",
        "                'generalized_true_positive_rate',\n",
        "                'mean_difference',\n",
        "                'negative_predictive_value',\n",
        "                'num_false_negatives',\n",
        "                'num_false_positives',\n",
        "                'num_generalized_false_negatives',\n",
        "                'num_generalized_false_positives',\n",
        "                'num_generalized_true_negatives',\n",
        "                'num_generalized_true_positives',\n",
        "                'num_instances',\n",
        "                'num_negatives',\n",
        "                'num_positives',\n",
        "                'num_pred_negatives',\n",
        "                'num_pred_positives',\n",
        "                'num_true_negatives',\n",
        "                'num_true_positives',\n",
        "                'performance_measures',\n",
        "                'positive_predictive_value',\n",
        "                'power',\n",
        "                'precision',\n",
        "                'ratio',\n",
        "                'recall',\n",
        "                'rich_subgroup',\n",
        "                'selection_rate',\n",
        "                'sensitivity',\n",
        "                'smoothed_empirical_differential_fairness',\n",
        "                'specificity',\n",
        "                'statistical_parity_difference',\n",
        "                'theil_index',\n",
        "                'true_negative_rate',\n",
        "                'true_positive_rate',\n",
        "                'true_positive_rate_difference']\n",
        "\n",
        "def compute_metrics(test_dataset,\n",
        "                    prediction_dataset,\n",
        "                    unprivileged_groups=[{'RAC1P': 2,'RAC1P': 3,'RAC1P': 4,'RAC1P': 5,'RAC1P': 6,'RAC1P': 7,'RAC1P': 8,'RAC1P': 9}],\n",
        "                    privileged_groups=[{'RAC1P': 1}],\n",
        "                    write_csv=True,\n",
        "                    csv_name=\"metrics.csv\",\n",
        "                    model_name=\"<no model name>\"):\n",
        "    \"\"\"\n",
        "    Given BinaryLabelDatasets test_dataset and prediction_dataset, compute all\n",
        "    AIF360 ClassificationMetrics and optionally store them in a .csv file.\n",
        "\n",
        "    Additionally, return a dictionary of all metrics.\n",
        "    \"\"\"\n",
        "\n",
        "    # create ClassificationMetric object with test set and predictions\n",
        "    # the object will include all metrics, see link below\n",
        "    # https://aif360.readthedocs.io/en/stable/modules/generated/aif360.metrics.ClassificationMetric.html\n",
        "\n",
        "    classification_metrics = ClassificationMetric(test_dataset,\n",
        "                                                  prediction_dataset,\n",
        "                                                  unprivileged_groups,\n",
        "                                                  privileged_groups)\n",
        "\n",
        "    metric_values = []\n",
        "\n",
        "    # compute all metrics specified in METRIC_NAMES\n",
        "    for metric_name in METRIC_NAMES[2:]:\n",
        "        try:\n",
        "            loc = {\"classification_metrics\": classification_metrics}\n",
        "            exec(f\"value = classification_metrics.{metric_name}()\", globals(), loc)\n",
        "            metric_values.append(loc[\"value\"])\n",
        "        except TypeError:\n",
        "            metric_values.append(None)\n",
        "\n",
        "    # insert ABROCA\n",
        "    metric_values.insert(0, abroca(test_dataset, prediction_dataset))\n",
        "\n",
        "    # insert model name\n",
        "    metric_values.insert(0, model_name)\n",
        "\n",
        "    # dictionary of all metrics in name:value format\n",
        "    metrics_dict = dict(zip(METRIC_NAMES, metric_values))\n",
        "\n",
        "    # write metrics to .csv file, if enabled\n",
        "    if write_csv:\n",
        "        with open(csv_name, 'w', encoding='utf8') as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow(METRIC_NAMES)\n",
        "            writer.writerow(metric_values)\n",
        "\n",
        "    return metrics_dict"
      ],
      "metadata": {
        "id": "_JVdK0Ic8TaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚öôÔ∏è Setup US Region Plotting"
      ],
      "metadata": {
        "id": "L3-_TSzNtAAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from Levenshtein import distance as levenshtein_distance"
      ],
      "metadata": {
        "id": "rbD1-k1Fs_Dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_us_states(state_codes, file_name=None):\n",
        "    \"\"\"\n",
        "    Generate a plot of given US states.\n",
        "\n",
        "    Args:\n",
        "        state_codes (list of str): State codes to plot.\n",
        "        file_name (str, optional): File name for generated plot. Defaults to None,\n",
        "                                   which means that the plot does not get saved.\n",
        "    \"\"\"\n",
        "    \n",
        "    states_values = [[state, random.rand()] for state in state_codes]\n",
        "    df = pd.DataFrame(states_values, columns=['state_code', 'value'])\n",
        "    fig = px.choropleth(df,\n",
        "                        locations='state_code',\n",
        "                        locationmode='USA-states',\n",
        "                        scope='usa',\n",
        "                        color='value')\n",
        "\n",
        "    fig.update_coloraxes(showscale=True)\n",
        "\n",
        "    if file_name is not None:\n",
        "        fig.write_image(file_name)\n",
        "\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "VmS_yRxdZ9n9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_us_regions_and_states(regions, metric_values, metric=None, infos=None, file_name_pre=None):\n",
        "    \"\"\"\n",
        "    Generate a plot of all regions together and a single plot for every region.\n",
        "\n",
        "    Args:\n",
        "        regions (list of str): region codes to plot.\n",
        "        metric_values (list of int): the values for the metric\n",
        "        metric (str): name of the used metric changes the used color range\n",
        "          possibilitys: \"accuracy\", \"abroca\", \"f1score\", \"disparate impact\"\n",
        "          if none -> \"Viridis\" will be used as colorscale and the range will be\n",
        "          the min and max value from metric_vales\n",
        "        infos (dict): a dictionary with information about the plots\n",
        "          example dict {trained_dataset = 'west coast geo',\n",
        "                        year = 2015,\n",
        "                        threshold = 500000,\n",
        "                        test_dataset = ['rural','west coast geo'],\n",
        "                        model_name = 'Metafair'}\n",
        "        file_name_pre (str, optional): adds a prefix to the generated filenames \n",
        "    \"\"\"\n",
        "    plot_us_states_cholormap(regions, metric_values, metric=metric, infos=infos, file_name_pre=file_name_pre)\n",
        "    plot_us_regions2(regions, metric_values, metric=metric, infos=infos, file_name_pre=file_name_pre)\n",
        "\n"
      ],
      "metadata": {
        "id": "OkMHyP8qaKEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_us_regions2(regions, metric_values, metric=None, infos=None, file_name_pre=None):\n",
        "    \"\"\"\n",
        "    Generate a single plot for every given US region.\n",
        "\n",
        "    Args:\n",
        "        regions (list of str): region codes to plot.\n",
        "        metric_values (list of int): the values for the metric\n",
        "        metric (str): name of the used metric changes the used color range\n",
        "          possibilitys: \"accuracy\", \"abroca\", \"f1score\", \"disparate impact\"\n",
        "          if none -> \"Viridis\" will be used as colorscale and the range will be\n",
        "          the min and max value from metric_vales\n",
        "        infos (dict): a dictionary with information about the plots\n",
        "          example dict {trained_dataset = 'west coast geo',\n",
        "                        year = 2015,\n",
        "                        threshold = 500000,\n",
        "                        test_dataset = ['rural','west coast geo'],\n",
        "                        model_name = 'Metafair'}\n",
        "        file_name_pre (str, optional): adds a prefix to the generated filenames\n",
        "    \"\"\"\n",
        "    states = regions_to_states(regions)\n",
        "    state_code_regions = []\n",
        "    for state_region in states:\n",
        "      state_code_regions.append(get_state_code(state_region))\n",
        "    color_continuous_midpoint = None\n",
        "    continous_scale = \"Viridis\"\n",
        "    metric_name = metric\n",
        "    if not metric:\n",
        "      range_color = [min(metric_values),max(metric_values)]\n",
        "      metric_name = \"value\"\n",
        "    elif metric == \"accuracy\":\n",
        "      range_color = [0,1]\n",
        "      continous_scale = \"RdYlGn\"\n",
        "    elif metric == \"abroca\":\n",
        "      range_color = [-1,1]\n",
        "      continous_scale = \"PuOr\"\n",
        "      color_continuous_midpoint=0\n",
        "    elif metric == \"f1score\":\n",
        "      continous_scale = \"RdYlGn\"\n",
        "      range_color = [0,1]\n",
        "    elif metric == \"disparate impact\":\n",
        "      continous_scale = \"PuOr\"\n",
        "      range_color = [0,2]\n",
        "      color_continuous_midpoint=1\n",
        "    else:\n",
        "      range_color = [min(metric_values),max(metric_values)]\n",
        "    figures= []\n",
        "    for count, state_code_region in enumerate(state_code_regions):\n",
        "      states_values = []\n",
        "      for state_code in state_code_region:\n",
        "        states_values.append([state_code, metric_values[count],regions[count]])\n",
        "      df = pd.DataFrame(states_values, columns=['state_code', metric_name,'regions'])\n",
        "      if not infos:\n",
        "        title = regions[count]\n",
        "      else:\n",
        "        title=\"\"\n",
        "        title = title + \"Trained \" + infos[\"model_name\"]+ \" \"+ \"on date from\"+ \" \"+ infos[\"year\"]+ \" \"+ \"with a threshold of\" + \" \" +infos[\"threshold\"]+\"<br>\"\n",
        "        title = title + \"Train Dataset: \" + infos[\"trained_dataset\"]+ \"<br>\"\n",
        "        title = title + \"Test Dataset: \" + regions[count] + \" \"\n",
        "      fig = px.choropleth(df,\n",
        "                          locations='state_code',\n",
        "                          locationmode='USA-states',\n",
        "                          scope='usa',\n",
        "                          color= metric_name,\n",
        "                          range_color= range_color,\n",
        "                          color_continuous_scale=continous_scale,\n",
        "                          color_continuous_midpoint=color_continuous_midpoint,\n",
        "                          hover_data=[metric_name, 'regions'],\n",
        "                          title=title)\n",
        "      fig.update_coloraxes(showscale=True)\n",
        "      figures.append(fig)\n",
        "    for count, f in enumerate(figures):\n",
        "      file_name= \"\"\n",
        "      if file_name_pre is not None:\n",
        "        file_name = file_name_pre+ \"_\"\n",
        "      if infos is not None:\n",
        "        file_name = file_name + infos[\"model_name\"]+ \"_\"+  infos[\"trained_dataset\"]+ \"_\"+ infos[\"year\"]+ \"_\"+infos[\"threshold\"]+\"_\"+ regions[count] + \"_\"+ infos[\"year\"]+ \"_\"+infos[\"threshold\"]\n",
        "      else:\n",
        "        file_name = file_name + regions[count]\n",
        "      file_name = file_name + \".png\"\n",
        "      f.write_image(file_name)\n",
        "      f.show()\n"
      ],
      "metadata": {
        "id": "4ROuiXhgt5Cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_us_states_cholormap(regions, metric_values, metric=None, infos=None, file_name_pre=None, ):\n",
        "    \"\"\"\n",
        "    Generate a plot of given US regions.\n",
        "\n",
        "    Args:\n",
        "        regions (list of str): region codes to plot.\n",
        "        metric_values (list of int): the values for the metric\n",
        "        metric (str): name of the used metric changes the used color range\n",
        "          possibilitys: \"accuracy\", \"abroca\", \"f1score\", \"disparate impact\"\n",
        "          if none -> \"Viridis\" will be used as colorscale and the range will be\n",
        "          the min and max value from metric_vales\n",
        "        infos (dict): a dictionary with information about the plots\n",
        "          example dict {trained_dataset = 'west coast geo',\n",
        "                        year = 2015,\n",
        "                        threshold = 500000,\n",
        "                        test_dataset = ['rural','west coast geo'],\n",
        "                        model_name = 'Metafair'}\n",
        "        file_name_pre (str, optional): adds a prefix to the generated filenames\n",
        "    \"\"\"\n",
        "    states = regions_to_states(regions)\n",
        "    state_code_regions = []\n",
        "\n",
        "    for state_region in states:\n",
        "      state_code_regions.append(get_state_code(state_region))\n",
        "    color_continuous_midpoint=None\n",
        "    continous_scale = \"Viridis\"\n",
        "    metric_name = metric\n",
        "    if not metric:\n",
        "      range_color = [min(metric_values),max(metric_values)]\n",
        "      metric_name = \"value\"\n",
        "    elif metric == \"accuracy\":\n",
        "      range_color = [0,1]\n",
        "      continous_scale = \"RdYlGn\"\n",
        "    elif metric == \"abroca\":\n",
        "      range_color = [-1,1]\n",
        "      continous_scale = \"PuOr\"\n",
        "      color_continuous_midpoint=0\n",
        "    elif metric == \"f1score\":\n",
        "      continous_scale = \"RdYlGn\"\n",
        "      range_color = [0,1]\n",
        "    elif metric == \"disparate impact\":\n",
        "      continous_scale = \"PuOr\"\n",
        "      range_color = [0,2]\n",
        "      color_continuous_midpoint=1\n",
        "    else:\n",
        "      range_color = [min(metric_values),max(metric_values)]\n",
        "    if not infos:\n",
        "      title = \"all selected data sets (mean values)\"\n",
        "    else:\n",
        "      title=\"\"\n",
        "      title = title + \"Trained \" + infos[\"model_name\"]+ \" \"+ \"on date from\"+ \" \"+ infos[\"year\"]+ \" \"+ \"with a threshold of\" + \" \" +infos[\"threshold\"]+\"<br>\"\n",
        "      title = title + \"Train Dataset: \" + infos[\"trained_dataset\"]+ \"<br>\"\n",
        "      title = title + \"Test Dataset: \" + \", \".join(regions)+ \" \"\n",
        "    states_values = []\n",
        "    state_code_dict = {}\n",
        "    for count, state_code_region in enumerate(state_code_regions):\n",
        "      for state_code in state_code_region:\n",
        "        if state_code in state_code_dict.keys():\n",
        "          state_code_dict[state_code].append((metric_values[count],regions[count]))\n",
        "        else:\n",
        "          state_code_dict[state_code]= [(metric_values[count],regions[count])]\n",
        "    for key_state_code in state_code_dict.items():\n",
        "      state_code_regions= []\n",
        "      values=[]\n",
        "      for value_region_tuple in key_state_code[1]:\n",
        "        values.append(value_region_tuple[0])\n",
        "        state_code_regions.append(value_region_tuple[1])\n",
        "      mean = sum(values)/len(key_state_code[1])\n",
        "      states_values.append([key_state_code[0], mean, state_code_regions, values])\n",
        "    df = pd.DataFrame(states_values, columns=['state_code', metric_name,'regions', 'values'])\n",
        "    fig = px.choropleth(df,\n",
        "                        locations='state_code',\n",
        "                        locationmode='USA-states',\n",
        "                        scope='usa',\n",
        "                        color=metric_name,\n",
        "                        color_continuous_scale=continous_scale,\n",
        "                        color_continuous_midpoint=color_continuous_midpoint,\n",
        "                        range_color= range_color,\n",
        "                        hover_data=[metric_name, 'regions', 'values'],\n",
        "                        title=title\n",
        "                        )\n",
        "    fig.update_coloraxes(showscale=True)\n",
        "    file_name = \"\"\n",
        "    if file_name_pre is not None:\n",
        "      file_name = file_name_pre + \"_\"\n",
        "    regions_name = \"_\".join(regions)\n",
        "    if infos is not None:\n",
        "      file_name = file_name + infos[\"model_name\"]+ \"_\"+  infos[\"trained_dataset\"]+ \"_\"+ infos[\"year\"]+ \"_\"+infos[\"threshold\"]+\"_\"+ regions_name + \"_\"+ infos[\"year\"]+ \"_\"+infos[\"threshold\"]\n",
        "    else:\n",
        "      file_name = file_name +  regions_name\n",
        "    file_name = file_name + \".png\"\n",
        "    fig.write_image(file_name)\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "AUfSd8E7aHiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def regions_to_states(regions: list):\n",
        "  \"\"\" Gets regions and returns the euqivalent states for the regions\n",
        "\n",
        "  Args:\n",
        "      regions (list): gets a list of regions\n",
        "\n",
        "  Returns:\n",
        "      list: gives a list of list where every list stand for a region with his states\n",
        "\n",
        "  Example:\n",
        "      regions_to_states(['west coast geo', 'urban']) ->  [['Alaska', 'California', 'Hawaii', 'Oregon', 'Washington'],['California ','New Jersey ',...]]\n",
        "  \"\"\"\n",
        "  states = []\n",
        "  for cur_dataset in regions:\n",
        "      #Determine current state list according to dataset preset\n",
        "      if cur_dataset == 'west coast geo':\n",
        "        states.append([\"Alaska\", \"California\", \"Hawaii\", \"Oregon\", \"Washington\"])\n",
        "      elif cur_dataset == 'west coast wiki':\n",
        "        states.append([\"Alaska\", \"Arizona\", \"California\", \"Colorado\", \"Hawaii\", \"Idaho\", \"Montana\", \"Nevada\", \"New Maxiko\", \"Oregon\", \"Utah\", \"Washington\", \"Wyoming\"])\n",
        "      elif cur_dataset == 'east coast geo':\n",
        "        states.append([\"Maine\", \"New Hampshire\", \"Massachusetts\", \"Rhode Island\", \"Connecticut\", \"New York\", \"New Jersey\", \"Delaware\", \"Maryland\", \"Virginia\", \"North Carolina\", \"South Carolina\", \"Georgia\", \"Florida\"])\n",
        "      elif cur_dataset == 'none coast geo':\n",
        "        states.append([\"Alabama\", \"Arkansas\", \"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Michigan\", \"Minnesota\", \"Mississippi\", \"Missouri\", \"Nebraska\", \"North Dakota\", \"Ohio\", \"Oklahoma\", \"Pennsylvania\", \"South Dakota\", \"Tennessee\", \"Texas\", \"Vermont\", \"West Virginia\", \"Wisconsin\", \"Puerto Rico\", \"Colorado\", \"Wyoming\", \"Montana\", \"Idaho\", \"Utah\", \"Nevada\", \"Arizona\", \"New Mexiko\"])\n",
        "      elif cur_dataset == 'none coast wiki':\n",
        "        states.append([\"Alabama\", \"Arkansas\", \"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Michigan\", \"Minnesota\", \"Mississippi\", \"Missouri\", \"Nebraska\", \"North Dakota\", \"Ohio\", \"Oklahoma\", \"Pennsylvania\", \"South Dakota\", \"Tennessee\", \"Texas\", \"Vermont\", \"West Virginia\", \"Wisconsin\", \"Puerto Rico\", \"Colorado\", \"Wyoming\", \"Montana\", \"Idaho\", \"Utah\", \"Nevada\", \"Arizona\", \"New Mexiko\"])\n",
        "      elif cur_dataset == 'urban':\n",
        "        states.append([\"California \",\"New Jersey \",\"Nevada \",\"Puerto Rico \",\"Massachusetts \",\"Hawaii \",\"Florida\",\"Rhode Island \",\"Utah \",\"Arizona \",\"Illinois \",\"Connecticut \",\"New York \",\"Maryland \",\"Colorado \",\"Texas \",\"Washington \",\"Delaware \",\"Oregon \"])\n",
        "      elif cur_dataset == 'rural':\n",
        "        states.append([\"Pennsylvania\", \"Ohio\", \"New Mexico\", \"Virginia\", \"Georgia\", \"Michigan\", \"Kansas\", \"Minnesota\", \"Louisiana\", \"Nebraska\", \"Indiana\", \"Idaho\", \"Missouri\", \"Wisconsin\", \"Tennessee\", \"South Carolina\", \"Oklahoma\", \"North Carolina\", \"Alaska\", \"Wyoming\", \"Iowa\", \"New Hampshire\", \"North Dakota\", \"Alabama\", \"Kentucky\", \"South Dakota\", \"Arkansas\", \"Montana\", \"Mississippi\", \"West Virginia\", \"Vermont\", \"Maine\", ])\n",
        "      elif cur_dataset == 'north':\n",
        "        states.append([\"Washington\",\"Oregon\",\"Idaho\",\"Montana\",\"Wyoming\",\"North Dakota\",\"South Dakota\",\"Nebraska\",\"Minnesota\",\"Iowa\",\"Wisconsin\",\"Illinois\",\"Michigan\",\"Indiana\",\"Ohio\",\"Pennslyvania\",\"New York\",\"Vermont\",\"New Hampshire\",\"Maine\",\"Massasuchets\",\"Conniticet\",\"New Jersey\"])\n",
        "      elif cur_dataset == 'south':\n",
        "        states.append([\"California\",\"Nevada\",\"Utah\",\"Arizona\",\"New Mexico\",\"Colorado\",\"Texas\",\"Oklahoma\",\"Kansas\",\"Arkansas\",\"Missouri\",\"Louisana\",\"Missisipi\",\"Alabama\",\"Tenesee\",\"Kentucky\",\"Georgia\",\"Florida\",\"South Carolina\",\"North Carolina\",\"Virginia\",\"West Virginia\",\"Delaware\",\"Maryland\"])\n",
        "      elif cur_dataset == 'all':\n",
        "        states.append([\"California\",\"Nevada\",\"Utah\",\"Arizona\",\"New Mexico\",\"Colorado\",\"Texas\",\"Oklahoma\",\"Kansas\",\"Arkansas\",\"Missouri\",\"Louisana\",\"Missisipi\",\"Alabama\",\"Tenesee\",\"Kentucky\",\"Georgia\",\"Florida\",\"South Carolina\",\"North Carolina\",\"Virginia\",\"West Virginia\",\"Delaware\",\"Maryland\",\"Washington\",\"Oregon\",\"Idaho\",\"Montana\",\"Wyoming\",\"North Dakota\",\"South Dakota\",\"Nebraska\",\"Minnesota\",\"Iowa\",\"Wisconsin\",\"Illinois\",\"Michigan\",\"Indiana\",\"Ohio\",\"Pennslyvania\",\"New York\",\"Vermont\",\"New Hampshire\",\"Maine\",\"Massasuchets\",\"Conniticet\",\"New Jersey\"])\n",
        "      else: \n",
        "        states.append([])\n",
        "  return states"
      ],
      "metadata": {
        "id": "AV7QqQ8SaGG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚öôÔ∏è Setup Helper functions"
      ],
      "metadata": {
        "id": "4HiWH7gHWhNM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports and helper functions that are not directly related to machine learning etc."
      ],
      "metadata": {
        "id": "iX3c4W8xIwOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os\n",
        "\n",
        "\"\"\"\n",
        "deafen can be used to reduce the output a function call generates.\n",
        "This is especially useful for the AIF360 models, as they don't have an inherent verbose parameter.\n",
        "\"\"\"\n",
        "\n",
        "def deafen(function, *args):\n",
        "    real_stdout = sys.stdout\n",
        "    sys.stdout = open(os.devnull, \"w\")\n",
        "    output = function(*args)\n",
        "    sys.stdout = real_stdout\n",
        "    return output\n",
        "\n",
        "##Credit Kamron Bhavnagri from Stackoverflow"
      ],
      "metadata": {
        "id": "j0XK07agWj9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import random"
      ],
      "metadata": {
        "id": "kavHCYNIuMeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Lj9vgzOvZZX"
      },
      "source": [
        "### ‚öôÔ∏è Setup Grid Training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The main function of our training framework.**\n",
        "\n",
        "It combines every previously introduced method into one singular call. \n",
        "\n",
        "Given all of the parameters, the method will train the selected model(s) on the selected data with all of the relevant parameters set as defined.\n",
        "\n",
        "How?\n",
        "Summary:\n",
        "\n",
        "      *   Check inputs\n",
        "      *   Download and generate all selected datasets\n",
        "      *   Split data into train and test sets (Holdout Testing)\n",
        "      *   Save every train dataset\n",
        "      Repeat for every model:\n",
        "        Repeat for every year:\n",
        "          Repeat for every threshold:\n",
        "            Repeat for every train dataset:\n",
        "              *   Train model on the dataset\n",
        "              *   Predict data for every dataset using trained model\n",
        "              *   Evaluate the predictions -> generate metrics\n",
        "              *   Save predictions and metrics\n",
        "      * If verbose is high enough: output plot of selected metric\n",
        "        \n",
        "\n",
        "Why in this way?\n",
        "\n",
        "This ensures that all datasets are evaluated fairly. \n",
        "\n",
        "It also allows uhe user to the directly if the results are dependent on the direction \n",
        "(e.g. maybe model from 2014 works better than a model from 2018 on data from 2018, but is this also the case for the data from 2014? We can check this easily)\n",
        "\n",
        "It also allows the user to be really flexible in what they want, without an extensive list of inputs. \n",
        "E.g. if the user had to add every test dataset individually it would reduce readibility and discourages users from experimenting as the syntax would be too complex.\n",
        "\n",
        "Each execution of this function generates a lot of data, however depending on what the user is interested in many things can be overlooked (Still the possibility of using it is already provided)\n",
        "\n"
      ],
      "metadata": {
        "id": "cEDeDvMlEMnz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6d8y1IWva6b"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "EXAMPLE PARAMETERS\n",
        "datasets = ['west coast geo','east coast geo', 'none coast geo', 'urban','rural','north','south','all']\n",
        "\n",
        "years = ['2014','2015','2016','2017','2018','2014 2015 2016']\n",
        "\n",
        "models = ['adversial debiasing']\n",
        "\n",
        "thresholds = ['50000']\n",
        "\n",
        "group_non_white = False\n",
        "\n",
        "verbose = 1\n",
        "\n",
        "seed = 12681\n",
        "\n",
        "metric = 'accuracy'\n",
        "\n",
        "file_prefix = None\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def grid_train_model_v2(datasets : list,years : list, models : list,thresholds = ['50000'],group_non_white = False,verbose=1,seed = 12681, metric='accuracy',file_prefix=None):\n",
        "  \"\"\"\n",
        "  Given a list of datasets, a list of years, a list of models, and optionally a list of thresholds, a list of additional paramaters and a boolean for grouping none whites,\n",
        "    the function trains all of the models on all of the datasets in accordance with the years, threshold and the none white grouping.\n",
        "\n",
        "  Args:\n",
        "      datasets (list of strings): List of datasets that should be evaluated. Each Model is trained on one of the datasets and evaluated on all datasets. Supported presets = 'west coast geo','west coast wiki','east coast geo','none coast geo','none coast wiki','urban','rural','north','south','all'\n",
        "      years (list of strings): List of years of the datasets. Possible values are 2014-2018 (inclusive) and also a combination of different years separated by a space. e.g. '2014' or '2014 2015 2016'\n",
        "      models (list of strings): List of models that should be evaluated. Each Model is trained both fairness aware and unaware. Supported models = 'adversial debiasing'\n",
        "      threshholds (list of strings, optional): List of thresholds that should be used to determine the labels of the datasets. By default it is ['50000'], the split used by the 'Adult Dataset' \n",
        "      parameters (list, optional): list of parameters that should be given to the models. Currently not used.\n",
        "      group_non_white(Bool,optional): Boolean Value that decides if non-white heritages are either grouped together or not. RAC1P = [-1,1] if True, RAC1P = [1,2,3,4,5,6,7,8,9] if False\n",
        "\n",
        "  Outputs:\n",
        "      Preds_'model'_'debias'_'trained dataset'_'years'_'threshold'_'tested dataset'_'years'_'threshold'_'group non-white'(pickled BinaryLabelDatasets): Both the predictions \n",
        "\n",
        "  Returns:\n",
        "      (list): predctions\n",
        "      (list): labels\n",
        "      (list): groups\n",
        "\n",
        "  ----------------------------------------------------------------\n",
        "      datasets\n",
        "      Possible Values: ['west coast geo','east coast geo', 'none coast geo', 'urban','rural','north','south','all']\n",
        "\n",
        "      Subgroup of our supported datasets. Every dataset as a single string.\n",
        "      years \n",
        "      Possible Values: ['2014','2015','2016','2017','2018','2014 2015 2016']\n",
        "\n",
        "      Every Year from 2014 - 2018 (inclusive) or a subgroup of those years. Everything as a single string\n",
        "\n",
        "      models \n",
        "      Possible Values: ['adversial debiasing', 'Metafair','PrejudiceRemover']\n",
        "\n",
        "      Subgroup of our supported Models. Every model as a single string.\n",
        "\n",
        "      Threshold \n",
        "      Possible Values: Any nonnegative number. Number should be a string. \n",
        "      Reasonable numbers could be: 30000,40000,50000 etc.\n",
        "\n",
        "      group_non_white\n",
        "      Possible Values: [True, False]\n",
        "\n",
        "      Whether every non-white race should be relabeled as \"Non-White\" or not.\n",
        "      If False: 9 Unique Race Values\n",
        "      If True:  2 Unique Race Values\n",
        "\n",
        "      verbose\n",
        "      Possible Values: [0,1,2]\n",
        "\n",
        "      Determines how much output the User receives during the training. \n",
        "      0 = no outputs, 1 = medium amount of output, 2 = high amount of output\n",
        "\n",
        "      seed\n",
        "      Possible Values: Any Number\n",
        "\n",
        "      Used as the initalization for the random number generation (e.g. affects the train-test split of the data)\n",
        "\n",
        "      metric\n",
        "      Possible Values: ['accuracy','f1score','abroca','disparate impact']\n",
        "\n",
        "      Determines the metric used for an overview plot at the end. The plot shows the value of the metric for the last trained model on every dataset (in the last year + threshold).\n",
        "\n",
        "      file_prefix\n",
        "      Possible Values: Any String\n",
        "\n",
        "      The prefix for the filename of the generated plots\n",
        "      \"\"\"\n",
        "\n",
        "  #Assert Datasets are as intended\n",
        "  assert datasets is not None\n",
        "  supported_sets = ['west coast geo','west coast wiki','east coast geo','none coast geo','none coast wiki','urban','rural','north','south','all']\n",
        "  for cur_dataset in datasets:\n",
        "    assert cur_dataset in supported_sets \n",
        "\n",
        "  #Assert years are as intended\n",
        "  assert years is not None\n",
        "  supported_years = ['2014','2015','2016','2017','2018']\n",
        "  for cur_years in years:\n",
        "    splitted_years = cur_years.split()\n",
        "    for year in splitted_years:\n",
        "      assert year in supported_years\n",
        "\n",
        "  #Assert models are as intended\n",
        "  assert models is not None\n",
        "  supported_models = ['adversial debiasing', 'Metafair','PrejudiceRemover']\n",
        "  for cur_model in models:\n",
        "    assert cur_model in supported_models\n",
        "\n",
        "\n",
        "  #Assert thresholds can be transformed into integers\n",
        "  assert thresholds is not None\n",
        "  for i in range(len(thresholds)):\n",
        "    threshold = thresholds[i]\n",
        "    try:\n",
        "      thresholds[i] = int(threshold)\n",
        "    except TypeError as err:\n",
        "      print('Error in Transformation:',err)\n",
        "\n",
        "\n",
        "  print('Now starting the Grid Training')\n",
        "\n",
        "  \"\"\"\n",
        "  Dataset Section\n",
        "  \"\"\"\n",
        "\n",
        "  list_of_all_datasets_train = []\n",
        "  list_of_all_datasets_test = []\n",
        "  name_of_datasets = []\n",
        "  list_of_years = []\n",
        "  list_of_thresholds = []\n",
        "\n",
        "  for cur_dataset in datasets:\n",
        "    #Determine current state list according to dataset preset\n",
        "    if cur_dataset == 'west coast geo':\n",
        "      state_list = [\"Alaska\", \"California\", \"Hawaii\", \"Oregon\", \"Washington\"] \n",
        "    elif cur_dataset == 'west coast wiki':\n",
        "      state_list = [\"Alaska\", \"Arizona\", \"California\", \"Colorado\", \"Hawaii\", \"Idaho\", \"Montana\", \"Nevada\", \"New Maxiko\", \"Oregon\", \"Utah\", \"Washington\", \"Wyoming\"] \n",
        "    elif cur_dataset == 'east coast geo':\n",
        "      state_list = [\"Maine\", \"New Hampshire\", \"Massachusetts\", \"Rhode Island\", \"Connecticut\", \"New York\", \"New Jersey\", \"Delaware\", \"Maryland\", \"Virginia\", \"North Carolina\", \"South Carolina\", \"Georgia\", \"Florida\"]\n",
        "    elif cur_dataset == 'none coast geo':\n",
        "      state_list = [\"Alabama\", \"Arkansas\", \"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Michigan\", \"Minnesota\", \"Mississippi\", \"Missouri\", \"Nebraska\", \"North Dakota\", \"Ohio\", \"Oklahoma\", \"Pennsylvania\", \"South Dakota\", \"Tennessee\", \"Texas\", \"Vermont\", \"West Virginia\", \"Wisconsin\", \"Puerto Rico\", \"Colorado\", \"Wyoming\", \"Montana\", \"Idaho\", \"Utah\", \"Nevada\", \"Arizona\", \"New Mexiko\"]\n",
        "    elif cur_dataset == 'none coast wiki':\n",
        "      state_list = [\"Alabama\", \"Arkansas\", \"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Michigan\", \"Minnesota\", \"Mississippi\", \"Missouri\", \"Nebraska\", \"North Dakota\", \"Ohio\", \"Oklahoma\", \"Pennsylvania\", \"South Dakota\", \"Tennessee\", \"Texas\", \"Vermont\", \"West Virginia\", \"Wisconsin\", \"Puerto Rico\", \"Colorado\", \"Wyoming\", \"Montana\", \"Idaho\", \"Utah\", \"Nevada\", \"Arizona\", \"New Mexiko\"]\n",
        "    elif cur_dataset == 'urban':\n",
        "      state_list = [\"California \",\"New Jersey \",\"Nevada \",\"Puerto Rico \",\"Massachusetts \",\"Hawaii \",\"Florida\",\"Rhode Island \",\"Utah \",\"Arizona \",\"Illinois \",\"Connecticut \",\"New York \",\"Maryland \",\"Colorado \",\"Texas \",\"Washington \",\"Delaware \",\"Oregon \"]\n",
        "    elif cur_dataset == 'rural':\n",
        "      state_list = [\"Pennsylvania\", \"Ohio\", \"New Mexico\", \"Virginia\", \"Georgia\", \"Michigan\", \"Kansas\", \"Minnesota\", \"Louisiana\", \"Nebraska\", \"Indiana\", \"Idaho\", \"Missouri\", \"Wisconsin\", \"Tennessee\", \"South Carolina\", \"Oklahoma\", \"North Carolina\", \"Alaska\", \"Wyoming\", \"Iowa\", \"New Hampshire\", \"North Dakota\", \"Alabama\", \"Kentucky\", \"South Dakota\", \"Arkansas\", \"Montana\", \"Mississippi\", \"West Virginia\", \"Vermont\", \"Maine\", ]\n",
        "    elif cur_dataset == 'north':\n",
        "      state_list = [\"Washington\",\"Oregon\",\"Idaho\",\"Montana\",\"Wyoming\",\"North Dakota\",\"South Dakota\",\"Nebraska\",\"Minnesota\",\"Iowa\",\"Wisconsin\",\"Illinois\",\"Michigan\",\"Indiana\",\"Ohio\",\"Pennslyvania\",\"New York\",\"Vermont\",\"New Hampshire\",\"Maine\",\"Massasuchets\",\"Conniticet\",\"New Jersey\"]\n",
        "    elif cur_dataset == 'south':\n",
        "      state_list = [\"California\",\"Nevada\",\"Utah\",\"Arizona\",\"New Mexico\",\"Colorado\",\"Texas\",\"Oklahoma\",\"Kansas\",\"Arkansas\",\"Missouri\",\"Louisana\",\"Missisipi\",\"Alabama\",\"Tenesee\",\"Kentucky\",\"Georgia\",\"Florida\",\"South Carolina\",\"North Carolina\",\"Virginia\",\"West Virginia\",\"Delaware\",\"Maryland\"]\n",
        "    elif cur_dataset == 'all':\n",
        "      state_list = [\"California\",\"Nevada\",\"Utah\",\"Arizona\",\"New Mexico\",\"Colorado\",\"Texas\",\"Oklahoma\",\"Kansas\",\"Arkansas\",\"Missouri\",\"Louisana\",\"Missisipi\",\"Alabama\",\"Tenesee\",\"Kentucky\",\"Georgia\",\"Florida\",\"South Carolina\",\"North Carolina\",\"Virginia\",\"West Virginia\",\"Delaware\",\"Maryland\",\"Washington\",\"Oregon\",\"Idaho\",\"Montana\",\"Wyoming\",\"North Dakota\",\"South Dakota\",\"Nebraska\",\"Minnesota\",\"Iowa\",\"Wisconsin\",\"Illinois\",\"Michigan\",\"Indiana\",\"Ohio\",\"Pennslyvania\",\"New York\",\"Vermont\",\"New Hampshire\",\"Maine\",\"Massasuchets\",\"Conniticet\",\"New Jersey\"]\n",
        "    else: \n",
        "      state_list = []\n",
        "\n",
        "    for cur_years in years:\n",
        "      #Get the current combination of years\n",
        "      splitted_years = cur_years.split()\n",
        "\n",
        "      for threshold in thresholds:\n",
        "        \"\"\"\n",
        "        if verbose == 0:\n",
        "          features_orig,labels_orig,group_orig,track_list_year_orig,track_list_state_orig = deafen(get_income_data_with_track,state_list,splitted_years,threshold,roup_non_white)\n",
        "        if verbose == 1:\n",
        "          print('-------------------------------------------------')\n",
        "          print('Creating dataset:',str(cur_dataset))\n",
        "          print('-------------------------------------------------')\n",
        "          features_orig,labels_orig,group_orig,track_list_year_orig,track_list_state_orig = deafen(get_income_data_with_track,state_list,splitted_years,threshold,group_non_white)\n",
        "        if verbose == 2:\n",
        "          features_orig,labels_orig,group_orig,track_list_year_orig,track_list_state_orig = get_income_data_with_track(state_list,splitted_years,threshold=threshold,group_non_white=group_non_white)\n",
        "        \"\"\"\n",
        "\n",
        "        print('-------------------------------------------------')\n",
        "        print('Creating dataset:',str(cur_dataset).replace(\" \", \"_\") + str(splitted_years))\n",
        "        print('-------------------------------------------------')\n",
        "        features_orig,labels_orig,group_orig,track_list_year_orig,track_list_state_orig = get_income_data_with_track(state_list,splitted_years,threshold=threshold,group_non_white=group_non_white)\n",
        "\n",
        "        df_all_orig = Get_Dataframe_from_all(features_orig,labels_orig)\n",
        "\n",
        "        df_features = label_numpy_data(features_orig)\n",
        "\n",
        "        aif_dataset = BinaryLabelDataset(df= df_all_orig,label_names = [\"Label\"],protected_attribute_names =['RAC1P'],privileged_protected_attributes = [1])\n",
        "\n",
        "        split_value= 0.7  # splits the data set into train and test data\n",
        "        dataset_orig_train, dataset_orig_test = aif_dataset.split([split_value], shuffle=True,seed=seed)\n",
        "\n",
        "        list_of_all_datasets_train.append(dataset_orig_train)\n",
        "        list_of_all_datasets_test.append(dataset_orig_test)\n",
        "        name_of_datasets.append(cur_dataset)\n",
        "        list_of_years.append(cur_years)\n",
        "        list_of_thresholds.append(threshold)\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        Pickle Datasets\n",
        "        \"\"\"\n",
        "\n",
        "        filename = 'Dataset_' + str(cur_dataset).replace(\" \", \"_\") + '_' + str(cur_years) + '_' + str(threshold) + 'group_non_white_' + str(group_non_white) + '.pickle'\n",
        "        outfile = open(filename,'wb')\n",
        "\n",
        "        pickle.dump(dataset_orig_test,outfile)\n",
        "        outfile.close()\n",
        "\n",
        "        if verbose == 2:\n",
        "          print('-------------------------------------------------')\n",
        "          print('Finished pickling the dataset:',str(cur_dataset))\n",
        "          print('-------------------------------------------------')\n",
        "\n",
        "  \"\"\"\n",
        "  Print the datasets and lists obtained\n",
        "  \"\"\"\n",
        "\n",
        "  #print('list_of_all_datasets_train',list_of_all_datasets_train)\n",
        "  #print('list_of_all_datasets_test',list_of_all_datasets_test)\n",
        "  #print('name_of_datasets',name_of_datasets)\n",
        "  #print('list_of_years',list_of_years)\n",
        "  #print('list_of_thresholds',list_of_thresholds)\n",
        "\n",
        "\n",
        "  if verbose == 1 or verbose == 2:\n",
        "    print('-------------------------------------------------')\n",
        "    print('Finished creating the datasets')\n",
        "    print('-------------------------------------------------')\n",
        "\n",
        "  \"\"\"\n",
        "  Model section\n",
        "  \"\"\"\n",
        "  #privileged_group = []\n",
        "\n",
        "  #unprivileged_group = []\n",
        "\n",
        "  if group_non_white == False:\n",
        "    privileged_groups = [{'RAC1P': 1}]\n",
        "    unprivileged_groups = [{'RAC1P': 2,'RAC1P': 3,'RAC1P': 4,'RAC1P': 5,'RAC1P': 6,'RAC1P': 7,'RAC1P': 8,'RAC1P': 9}]\n",
        "  if group_non_white == True:\n",
        "    privileged_groups = [{'RAC1P': 1}]\n",
        "    unprivileged_groups = [{'RAC1P': -1}]\n",
        "\n",
        "  list_of_metrics_from_last_model = []\n",
        "  list_of_datasets_for_last_model = []\n",
        "\n",
        "  if metric == 'disparate impact':\n",
        "    metric_key = 'disparate_impact'\n",
        "  else:\n",
        "    metric_key = metric\n",
        "\n",
        "  for cur_dataset_num in range(len(name_of_datasets)):\n",
        "    for cur_model in models:\n",
        "      if cur_model == 'adversial debiasing':\n",
        "        \"\"\"\n",
        "        First learn the debiased model\n",
        "        \"\"\"\n",
        "        sess = tf.compat.v1.Session()\n",
        "\n",
        "        cur_name = 'adv_deb_'+ str(name_of_datasets[cur_dataset_num]).replace(\" \", \"_\")+ str(list_of_years[cur_dataset_num]) + str(list_of_thresholds[cur_dataset_num]) +  '_debias' + str(random.randrange(1,10000))\n",
        "        \n",
        "        debias_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
        "                      unprivileged_groups = unprivileged_groups,\n",
        "                      scope_name=cur_name,\n",
        "                      debias=True,\n",
        "                      sess=sess)\n",
        "\n",
        "        #print(list_of_all_datasets_train[cur_dataset_num])\n",
        "\n",
        "        if verbose == 0:\n",
        "          deafen(debias_model.fit,list_of_all_datasets_train[cur_dataset_num])\n",
        "        if verbose == 1:\n",
        "          print('-------------------------------------------------')\n",
        "          print('Now starting training of adv. Deb. --- debiased model on dataset:' + str(name_of_datasets[cur_dataset_num]) + str(list_of_years[cur_dataset_num]) + str(list_of_thresholds[cur_dataset_num]))\n",
        "          print('-------------------------------------------------')\n",
        "          deafen(debias_model.fit,list_of_all_datasets_train[cur_dataset_num])\n",
        "        if verbose == 2:\n",
        "          debias_model.fit(list_of_all_datasets_train[cur_dataset_num])\n",
        "\n",
        "        \"\"\"\n",
        "        Second learn the biased model\n",
        "        \"\"\"\n",
        "\n",
        "        cur_name = 'adv_deb_'+ str(name_of_datasets[cur_dataset_num]).replace(\" \", \"_\") + str(list_of_years[cur_dataset_num]) + str(list_of_thresholds[cur_dataset_num]) + '_bias' + str(random.randrange(1,10000))\n",
        "        \n",
        "        bias_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
        "                      unprivileged_groups = unprivileged_groups,\n",
        "                      scope_name=cur_name,\n",
        "                      debias=False,\n",
        "                      sess=sess)\n",
        "\n",
        "        if verbose == 0:\n",
        "          deafen(bias_model.fit,list_of_all_datasets_train[cur_dataset_num])\n",
        "        if verbose == 1:\n",
        "          print('-------------------------------------------------')\n",
        "          print('Now starting training of adv. Deb. --- biased model on dataset:' + str(name_of_datasets[cur_dataset_num]) + ' year ' + str(list_of_years[cur_dataset_num]) + ' threshold ' + str(list_of_thresholds[cur_dataset_num]) )\n",
        "          print('-------------------------------------------------')\n",
        "          deafen(bias_model.fit,list_of_all_datasets_train[cur_dataset_num])\n",
        "        if verbose == 2:\n",
        "          bias_model.fit(list_of_all_datasets_train[cur_dataset_num])\n",
        "\n",
        "        \"\"\"\n",
        "        Predict the model on all datasets\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        for cur_test_num in range(len(list_of_all_datasets_test)):\n",
        "          preds_debias = debias_model.predict(list_of_all_datasets_test[cur_test_num])\n",
        "\n",
        "          preds_bias = bias_model.predict(list_of_all_datasets_test[cur_test_num])\n",
        "\n",
        "\n",
        "          \"\"\"\n",
        "          Pickle Predictions\n",
        "          \"\"\"\n",
        "          filename = 'Preds_' + 'adv_deb_'+'debias_'+ str(name_of_datasets[cur_dataset_num]) + '_' + str(list_of_years[cur_dataset_num]) + '_' + str(list_of_thresholds[cur_dataset_num]) + '_' + str(name_of_datasets[cur_test_num]) + '_' + str(list_of_years[cur_test_num]) + '_' + str(list_of_thresholds[cur_test_num]) + '_' + 'group_non_white_' + str(group_non_white) + '.pickle'\n",
        "          outfile = open(filename,'wb')\n",
        "\n",
        "          pickle.dump(preds_debias,outfile)\n",
        "          outfile.close()\n",
        "\n",
        "          filename = 'Preds_' + 'adv_deb_'+'bias_'+ str(name_of_datasets[cur_dataset_num]) + '_' + str(list_of_years[cur_dataset_num]) + '_' + str(list_of_thresholds[cur_dataset_num]) + '_' + str(name_of_datasets[cur_test_num]) + '_' + str(list_of_years[cur_test_num]) + '_' + str(list_of_thresholds[cur_test_num]) + '_' + 'group_non_white_' + str(group_non_white) + '.pickle'\n",
        "          outfile = open(filename,'wb')\n",
        "\n",
        "          pickle.dump(preds_bias,outfile)\n",
        "          outfile.close()\n",
        "\n",
        "\n",
        "          if verbose == 1 or verbose == 2:\n",
        "            print('-------------------------------------------------')\n",
        "            print('Finished pickling the predictions')\n",
        "            print('-------------------------------------------------')\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "          \"\"\"\n",
        "          Evaluate predictions\n",
        "          \"\"\"        \n",
        "          #Debiased Model (returns dict and writes results to .csv file)\n",
        "          csv_name = 'metrics_' + 'adv_deb_'+'debias_'+ str(name_of_datasets[cur_dataset_num]) + '_' + str(list_of_years[cur_dataset_num]) + '_' + str(list_of_thresholds[cur_dataset_num]) + '_' + str(name_of_datasets[cur_test_num]) + '_' + str(list_of_years[cur_test_num]) + '_' + str(list_of_thresholds[cur_test_num]) + '_' + 'group_non_white_' + str(group_non_white) + '.csv'\n",
        "          model_name ='adv_deb_'+'debias_'+ str(name_of_datasets[cur_dataset_num]) + '_' + str(list_of_years[cur_dataset_num]) + '_' + str(list_of_thresholds[cur_dataset_num]) + '_' + str(name_of_datasets[cur_test_num]) + '_' + str(list_of_years[cur_test_num]) + '_' + str(list_of_thresholds[cur_test_num]) + '_' + 'group_non_white_' + str(group_non_white)\n",
        "\n",
        "\n",
        "          metrics_dict = compute_metrics( list_of_all_datasets_test[cur_test_num],\n",
        "                                          preds_debias,\n",
        "                                          csv_name=csv_name,\n",
        "                                          model_name = model_name,\n",
        "                                          unprivileged_groups=unprivileged_groups,\n",
        "                                          privileged_groups = privileged_groups\n",
        "                                         )\n",
        "          \n",
        "          if verbose > 0:\n",
        "            if list_of_years[cur_dataset_num] == list_of_years[-1]:\n",
        "              if name_of_datasets[cur_dataset_num] == name_of_datasets[-1]:\n",
        "                if list_of_thresholds[-1] == list_of_thresholds[cur_dataset_num]:\n",
        "                  if list_of_years[cur_test_num] == list_of_years[-1]:\n",
        "                    if list_of_thresholds[-1] == list_of_thresholds[cur_test_num]:\n",
        "                    #Get the Results of the last trained model and get all metrics of datasets from the same year as the model (On the same threshold)\n",
        "                      if metric_key == 'f1score':\n",
        "                        cur_prec =  metrics_dict['precision']\n",
        "                        cur_recall = metrics_dict['recall']\n",
        "                        cur_f1score = 2 * (cur_prec * cur_recall) / (cur_prec + cur_recall) \n",
        "                        list_of_metrics_from_last_model.append(cur_f1score)\n",
        "                      else: \n",
        "                        list_of_metrics_from_last_model.append(metrics_dict[metric_key])\n",
        "                      list_of_datasets_for_last_model.append(name_of_datasets[cur_test_num])\n",
        "            \n",
        "          #Biased Model (returns dict and writes results to .csv file)\n",
        "\n",
        "          csv_name = 'metrics_' + 'adv_deb_'+'bias_'+ str(name_of_datasets[cur_dataset_num]) + '_' + str(list_of_years[cur_dataset_num]) + '_' + str(list_of_thresholds[cur_dataset_num]) + '_' + str(name_of_datasets[cur_test_num]) + '_' + str(list_of_years[cur_test_num]) + '_' + str(list_of_thresholds[cur_test_num]) + '_' + 'group_non_white_' + str(group_non_white) + '.csv'\n",
        "          model_name ='adv_deb_'+'bias_'+ str(name_of_datasets[cur_dataset_num]) + '_' + str(list_of_years[cur_dataset_num]) + '_' + str(list_of_thresholds[cur_dataset_num]) + '_' + str(name_of_datasets[cur_test_num]) + '_' + str(list_of_years[cur_test_num]) + '_' + str(list_of_thresholds[cur_test_num]) + '_' + 'group_non_white_' + str(group_non_white)\n",
        "\n",
        "          metrics_dict = compute_metrics( list_of_all_datasets_test[cur_test_num],\n",
        "                                          preds_bias,\n",
        "                                          model_name = model_name,\n",
        "                                          csv_name=csv_name,\n",
        "                                          unprivileged_groups=unprivileged_groups,\n",
        "                                          privileged_groups = privileged_groups\n",
        "                                         )\n",
        "          \n",
        "          if verbose == 1 or verbose == 2:\n",
        "            print('-------------------------------------------------')\n",
        "            print('Finished computing the metrics')\n",
        "            print('-------------------------------------------------')\n",
        "\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        Print progress\n",
        "        \"\"\"\n",
        "        \n",
        "        print('-------------------------------------------------')\n",
        "        print('Finished Dataset: ',name_of_datasets[cur_dataset_num])\n",
        "        print('-------------------------------------------------')\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        Remove remaining portions of the previous model\n",
        "        \"\"\"\n",
        "\n",
        "        if cur_model == 'adversial debiasing':\n",
        "          sess.close()\n",
        "\n",
        "        print('-------------------------------------------------')\n",
        "        print('Finished closing the session for adv. Deb.')\n",
        "        print('-------------------------------------------------')\n",
        "\n",
        "\n",
        "    if cur_model == 'Metafair':\n",
        "      meta_fair_sr = MetaFairClassifier(sensitive_attr=\"RAC1P\",type=\"sr\",seed = seed)\n",
        "\n",
        "      \"\"\"\n",
        "      Train the model\n",
        "      \"\"\"\n",
        "      if verbose == 0:\n",
        "          deafen(meta_fair_sr.fit,list_of_all_datasets_train[cur_dataset_num])\n",
        "      if verbose == 1:\n",
        "        print('-------------------------------------------------')\n",
        "        print('Now starting training of Metafair model on dataset:' + str(name_of_datasets[cur_dataset_num]) + ' year ' + str(list_of_years[cur_dataset_num]) + ' threshold ' + str(list_of_thresholds[cur_dataset_num]) )\n",
        "        print('-------------------------------------------------')\n",
        "        deafen(meta_fair_sr.fit,list_of_all_datasets_train[cur_dataset_num])\n",
        "      if verbose == 2:\n",
        "        meta_fair_sr.fit(list_of_all_datasets_train[cur_dataset_num])\n",
        "\n",
        "\n",
        "      \"\"\"\n",
        "      Predict the model on all datasets\n",
        "      \"\"\"\n",
        "\n",
        "\n",
        "      for cur_test_num in range(len(list_of_all_datasets_test)):\n",
        "        preds_metafair = meta_fair_sr.predict(list_of_all_datasets_test[cur_test_num])\n",
        "\n",
        "      \n",
        "\n",
        "        \"\"\"\n",
        "        Pickle Predictions\n",
        "        \"\"\"\n",
        "        filename = 'Preds_' + 'Metafair_'+ str(name_of_datasets[cur_dataset_num]) + '_' + str(list_of_years[cur_dataset_num]) + '_' + str(list_of_thresholds[cur_dataset_num]) + '_' + str(name_of_datasets[cur_test_num]) + '_' + str(list_of_years[cur_test_num]) + '_' + str(list_of_thresholds[cur_test_num]) + '_' + 'group_non_white_' + str(group_non_white) + '.pickle'\n",
        "        outfile = open(filename,'wb')\n",
        "\n",
        "        pickle.dump(preds_metafair,outfile)\n",
        "        outfile.close()\n",
        "\n",
        "\n",
        "        if verbose == 1 or verbose == 2:\n",
        "          print('-------------------------------------------------')\n",
        "          print('Finished pickling the predictions')\n",
        "          print('-------------------------------------------------')\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "        \"\"\"\n",
        "        Evaluate predictions\n",
        "        \"\"\"        \n",
        "        #Meta fair \n",
        "        csv_name = 'metrics_' + 'metafair_'+ str(name_of_datasets[cur_dataset_num]) + '_' + str(list_of_years[cur_dataset_num]) + '_' + str(list_of_thresholds[cur_dataset_num]) + '_' + str(name_of_datasets[cur_test_num]) + '_' + str(list_of_years[cur_test_num]) + '_' + str(list_of_thresholds[cur_test_num]) + '_' + 'group_non_white_' + str(group_non_white) + '.csv'\n",
        "        model_name = 'metafair_' + str(name_of_datasets[cur_dataset_num]) + '_' + str(list_of_years[cur_dataset_num]) + '_' + str(list_of_thresholds[cur_dataset_num]) + '_' + str(name_of_datasets[cur_test_num]) + '_' + str(list_of_years[cur_test_num]) + '_' + str(list_of_thresholds[cur_test_num]) + '_' + 'group_non_white_' + str(group_non_white)\n",
        "\n",
        "\n",
        "        metrics_dict = compute_metrics( list_of_all_datasets_test[cur_test_num],\n",
        "                                        preds_metafair,\n",
        "                                        csv_name=csv_name,\n",
        "                                        model_name = model_name,\n",
        "                                        unprivileged_groups=unprivileged_groups,\n",
        "                                        privileged_groups = privileged_groups\n",
        "                                      )\n",
        "        \n",
        "        if verbose > 0:\n",
        "          if list_of_years[cur_dataset_num] == list_of_years[-1]:\n",
        "            if name_of_datasets[cur_dataset_num] == name_of_datasets[-1]:\n",
        "              if list_of_thresholds[-1] == list_of_thresholds[cur_dataset_num]:\n",
        "                if list_of_years[cur_test_num] == list_of_years[-1]:\n",
        "                  if list_of_thresholds[-1] == list_of_thresholds[cur_test_num]:\n",
        "                  #Get the Results of the last trained model and get all metrics of datasets from the same year as the model (On the same threshold)\n",
        "                    if metric_key == 'f1score':\n",
        "                      cur_prec =  metrics_dict['precision']\n",
        "                      cur_recall = metrics_dict['recall']\n",
        "                      cur_f1score = 2 * (cur_prec * cur_recall) / (cur_prec + cur_recall) \n",
        "                      list_of_metrics_from_last_model.append(cur_f1score)\n",
        "                    else: \n",
        "                      list_of_metrics_from_last_model.append(metrics_dict[metric_key])\n",
        "                    list_of_datasets_for_last_model.append(name_of_datasets[cur_test_num])\n",
        "\n",
        "\n",
        "    if cur_model == 'PrejudiceRemover':\n",
        "      prejudiceremover_model= PrejudiceRemover(sensitive_attr=\"RAC1P\")\n",
        "\n",
        "      \"\"\"\n",
        "      Train the model\n",
        "      \"\"\"\n",
        "      if verbose == 0:\n",
        "          deafen(prejudiceremover_model.fit,list_of_all_datasets_train[cur_dataset_num])\n",
        "      if verbose == 1:\n",
        "        print('-------------------------------------------------')\n",
        "        print('Now starting training of PrejudiceRemover model on dataset:' + str(name_of_datasets[cur_dataset_num]) + ' year ' + str(list_of_years[cur_dataset_num]) + ' threshold ' + str(list_of_thresholds[cur_dataset_num]) )\n",
        "        print('-------------------------------------------------')\n",
        "        deafen(prejudiceremover_model.fit,list_of_all_datasets_train[cur_dataset_num])\n",
        "      if verbose == 2:\n",
        "        prejudiceremover_model.fit(list_of_all_datasets_train[cur_dataset_num])\n",
        "\n",
        "\n",
        "      \"\"\"\n",
        "      Predict the model on all datasets\n",
        "      \"\"\"\n",
        "\n",
        "\n",
        "      for cur_test_num in range(len(list_of_all_datasets_test)):\n",
        "        preds_prejudiceremover = prejudiceremover_model.predict(list_of_all_datasets_test[cur_test_num])\n",
        "\n",
        "      \n",
        "\n",
        "        \"\"\"\n",
        "        Pickle Predictions\n",
        "        \"\"\"\n",
        "        filename = 'Preds_' + 'prejudiceremover_'+ str(name_of_datasets[cur_dataset_num]) + '_' + str(list_of_years[cur_dataset_num]) + '_' + str(list_of_thresholds[cur_dataset_num]) + '_' + str(name_of_datasets[cur_test_num]) + '_' + str(list_of_years[cur_test_num]) + '_' + str(list_of_thresholds[cur_test_num]) + '_' + 'group_non_white_' + str(group_non_white) + '.pickle'\n",
        "        outfile = open(filename,'wb')\n",
        "\n",
        "        pickle.dump(preds_prejudiceremover,outfile)\n",
        "        outfile.close()\n",
        "\n",
        "\n",
        "        if verbose == 1 or verbose == 2:\n",
        "          print('-------------------------------------------------')\n",
        "          print('Finished pickling the predictions')\n",
        "          print('-------------------------------------------------')\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "        \"\"\"\n",
        "        Evaluate predictions\n",
        "        \"\"\"        \n",
        "        #Meta fair \n",
        "        csv_name = 'metrics_' + 'PrejudiceRemover_'+ str(name_of_datasets[cur_dataset_num]) + '_' + str(list_of_years[cur_dataset_num]) + '_' + str(list_of_thresholds[cur_dataset_num]) + '_' + str(name_of_datasets[cur_test_num]) + '_' + str(list_of_years[cur_test_num]) + '_' + str(list_of_thresholds[cur_test_num]) + '_' + 'group_non_white_' + str(group_non_white) + '.csv'\n",
        "        model_name = 'PrejudiceRemover_'+ str(name_of_datasets[cur_dataset_num]) + '_' + str(list_of_years[cur_dataset_num]) + '_' + str(list_of_thresholds[cur_dataset_num]) + '_' + str(name_of_datasets[cur_test_num]) + '_' + str(list_of_years[cur_test_num]) + '_' + str(list_of_thresholds[cur_test_num]) + '_' + 'group_non_white_' + str(group_non_white)\n",
        "\n",
        "\n",
        "        metrics_dict = compute_metrics( list_of_all_datasets_test[cur_test_num],\n",
        "                                        preds_prejudiceremover,\n",
        "                                        csv_name=csv_name,\n",
        "                                        model_name = model_name,\n",
        "                                        unprivileged_groups=unprivileged_groups,\n",
        "                                        privileged_groups = privileged_groups\n",
        "                                      )\n",
        "        if verbose > 0:\n",
        "          if list_of_years[cur_dataset_num] == list_of_years[-1]:\n",
        "            if name_of_datasets[cur_dataset_num] == name_of_datasets[-1]:\n",
        "              if list_of_thresholds[-1] == list_of_thresholds[cur_dataset_num]:\n",
        "                if list_of_years[cur_test_num] == list_of_years[-1]:\n",
        "                  if list_of_thresholds[-1] == list_of_thresholds[cur_test_num]:\n",
        "                  #Get the Results of the last trained model and get all metrics of datasets from the same year as the model (On the same threshold)\n",
        "                    if metric_key == 'f1score':\n",
        "                      cur_prec =  metrics_dict['precision']\n",
        "                      cur_recall = metrics_dict['recall']\n",
        "                      cur_f1score = 2 * (cur_prec * cur_recall) / (cur_prec + cur_recall) \n",
        "                      list_of_metrics_from_last_model.append(cur_f1score)\n",
        "                    else: \n",
        "                      list_of_metrics_from_last_model.append(metrics_dict[metric_key])\n",
        "                    list_of_datasets_for_last_model.append(name_of_datasets[cur_test_num])\n",
        "\n",
        "\n",
        "\n",
        "  if verbose == 2:\n",
        "    print('-------------------------------------------------')\n",
        "    print('Now printing the last metrics Dictionary')\n",
        "    print(metrics_dict)\n",
        "    print('-------------------------------------------------')\n",
        "    \n",
        "    \n",
        "\n",
        "  if verbose == 1 or verbose == 2:\n",
        "    print('-------------------------------------------------')\n",
        "    print('Thank you for using this model. The Grid Training is now complete.')\n",
        "    print('-------------------------------------------------')\n",
        "    print('Now outputting the generated plots for the metrics of the latest trained model')\n",
        "    if models[-1:] == 'adversial debiasing':\n",
        "       print('Model:',models[-1:],'(Note: We only use the metrics of the debiased model)')\n",
        "    else:\n",
        "       print('Model:',models[-1:])\n",
        "    print('Trained on Year:',str(list_of_years[-1:]),'Dataset',str(name_of_datasets[-1:]),'Threshold:',str(list_of_thresholds[-1:]))\n",
        "    #print('Trained on Year:',list_of_years,'Datasets',,'Threshold:',))\n",
        "\n",
        "    print('-------------------------------------------------')\n",
        "    #print(list_of_datasets_for_last_model)\n",
        "    #print(list_of_metrics_from_last_model)\n",
        "    #print(metric)\n",
        "    #print(file_name)\n",
        "\n",
        "    information_dict = {\n",
        "            \"trained_dataset\" : str(name_of_datasets[-1]),\n",
        "            \"year\" : str(list_of_years[-1]),\n",
        "            \"threshold\" : str(list_of_thresholds[-1]),\n",
        "            \"model_name\" : models[-1],\n",
        "    }\n",
        "\n",
        "    plot_us_regions_and_states(list_of_datasets_for_last_model,list_of_metrics_from_last_model,infos = information_dict ,metric = metric,file_name_pre=file_prefix)\n",
        "    \n",
        "    print('-------------------------------------------------')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# üß© Grid Training Examples"
      ],
      "metadata": {
        "id": "4RgkkcTVvf8M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section shows the wide range of possible inputs our Grid Training framework can utilize.\n",
        "\n"
      ],
      "metadata": {
        "id": "-6ZYCllP_f6B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "\n",
        "When the setup finished, you can <font color='orange'>run the cell below</font> to start the interactive grid training.\n",
        "\n",
        "Here, you can easily generate new data by setting your own parameters. Simply select all of the parameters you are interested in and then the <font color='orange'>run the cell below the paramters</font>. The Training will start.\n",
        "\n",
        "Note: The interesting information is in the metrics csv file."
      ],
      "metadata": {
        "id": "4iLjNXUpz0xT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation Guidelines**\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Parameter</th>\n",
        "    <th>Meaning</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Evaluation Mode</td>\n",
        "    <td>Evaluate different models tested on the same dataset => mode <i>'test'</i> <br></br>Evaluate model trained on one dataset on multiple other datasets => mode <i>'train'</i></td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Evaluation Dataset</td>\n",
        "    <td>For which dataset do you want to explore metrics?</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Evaluation Year</td>\n",
        "    <td>For which years do you want to explore metrics?</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Income Threshold</td>\n",
        "    <td>For which threshold do you want to explore metrics?</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Metric</td>\n",
        "    <td>Which metric do you want to plot?<br></br>Click <i>'Show Advanced Metrics'</i> to see all collected metrics.</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Legend Position</td>\n",
        "    <td>(Where) do you want the legend to be placed?<br></br>Choose <i>'best'</i> for automatic placement.</td>\n",
        "  </tr>  \n",
        "</table>\n",
        "<br/><br/>\n",
        "\n",
        "**Have fun exploring the Data!** "
      ],
      "metadata": {
        "id": "e5Q277Ntr4xJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = ['rural']\n",
        "\n",
        "years = ['2014']\n",
        "\n",
        "models = ['Metafair'] \n",
        "\n",
        "thresholds = ['50000']\n",
        "\n",
        "group_non_white = True \n",
        "\n",
        "verbose = 2 \n",
        "\n",
        "metric='accuracy'\n",
        "\n",
        "grid_train_model_v2(datasets,years, models,thresholds,group_non_white,verbose)"
      ],
      "metadata": {
        "id": "0eItR7N1vcFh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c1cff7bf-4e90-4b38-9228-470b1e069e39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now starting the Grid Training\n",
            "-------------------------------------------------\n",
            "Creating dataset: rural['2014']\n",
            "-------------------------------------------------\n",
            "-------------------------------------------------\n",
            "Finished pickling the dataset: rural\n",
            "-------------------------------------------------\n",
            "-------------------------------------------------\n",
            "Finished creating the datasets\n",
            "-------------------------------------------------\n",
            "-------------------------------------------------\n",
            "Finished pickling the predictions\n",
            "-------------------------------------------------\n",
            "-------------------------------------------------\n",
            "Now printing the last metrics Dictionary\n",
            "{'model_name': 'metafair_rural_2014_50000_rural_2014_50000_group_non_white_True', 'abroca': 0.02311308729026007, 'accuracy': 0.7188710621852676, 'average_abs_odds_difference': 0.10498261851487309, 'average_odds_difference': 0.10498261851487309, 'base_rate': 0.2818034898700082, 'between_all_groups_coefficient_of_variation': 0.0776560806682044, 'between_all_groups_generalized_entropy_index': 0.001507616716186667, 'between_all_groups_theil_index': 0.001461753647822268, 'between_group_coefficient_of_variation': 0.0776560806682044, 'between_group_generalized_entropy_index': 0.001507616716186667, 'between_group_theil_index': 0.001461753647822268, 'binary_confusion_matrix': {'TP': 49648.0, 'FP': 49504.0, 'TN': 103813.0, 'FN': 10510.0}, 'coefficient_of_variation': 0.5952128619133916, 'consistency': array([0.80262138]), 'difference': None, 'differential_fairness_bias_amplification': -0.3383532801831338, 'disparate_impact': 1.1353484752500687, 'equal_opportunity_difference': 0.08186953122461305, 'error_rate': 0.28112893781473236, 'error_rate_difference': 0.10125952233319113, 'error_rate_ratio': 1.3835173335562836, 'false_discovery_rate': 0.49927384218170084, 'false_discovery_rate_difference': 0.21152716210418093, 'false_discovery_rate_ratio': 1.4602186697835657, 'false_negative_rate': 0.1747066059376974, 'false_negative_rate_difference': -0.08186953122461305, 'false_negative_rate_ratio': 0.5549850880932928, 'false_omission_rate': 0.09193250701958486, 'false_omission_rate_difference': -0.06154003803810013, 'false_omission_rate_ratio': 0.3927004580443909, 'false_positive_rate': 0.32288656835184615, 'false_positive_rate_difference': 0.12809570580513313, 'false_positive_rate_ratio': 1.4291984473767292, 'generalized_binary_confusion_matrix': {'GTP': 37825.53849058953, 'GFP': 74228.52803384213, 'GTN': 79088.47196615786, 'GFN': 22332.46150941047}, 'generalized_entropy_index': 0.08856958774678254, 'generalized_false_negative_rate': 0.37123011917634346, 'generalized_false_positive_rate': 0.4841506684440873, 'generalized_true_negative_rate': 0.5158493315559126, 'generalized_true_positive_rate': 0.6287698808236566, 'mean_difference': 0.06146003504033859, 'negative_predictive_value': 0.9080674929804151, 'num_false_negatives': 10510.0, 'num_false_positives': 49504.0, 'num_generalized_false_negatives': 22332.46150941047, 'num_generalized_false_positives': 74228.52803384213, 'num_generalized_true_negatives': 79088.47196615786, 'num_generalized_true_positives': 37825.53849058953, 'num_instances': 213475.0, 'num_negatives': 153317.0, 'num_positives': 60158.0, 'num_pred_negatives': 114323.0, 'num_pred_positives': 99152.0, 'num_true_negatives': 103813.0, 'num_true_positives': 49648.0, 'performance_measures': {'TPR': 0.8252933940623026, 'TNR': 0.6771134316481539, 'FPR': 0.32288656835184615, 'FNR': 0.1747066059376974, 'GTPR': 0.6287698808236566, 'GTNR': 0.5158493315559126, 'GFPR': 0.4841506684440873, 'GFNR': 0.37123011917634346, 'PPV': 0.5007261578182992, 'NPV': 0.9080674929804151, 'FDR': 0.49927384218170084, 'FOR': 0.09193250701958486, 'ACC': 0.7188710621852676}, 'positive_predictive_value': 0.5007261578182992, 'power': 49648.0, 'precision': 0.5007261578182992, 'ratio': None, 'recall': 0.8252933940623026, 'rich_subgroup': None, 'selection_rate': 0.46446656517156576, 'sensitivity': 0.8252933940623026, 'smoothed_empirical_differential_fairness': 0.4652915042835315, 'specificity': 0.6771134316481539, 'statistical_parity_difference': 0.06146003504033859, 'theil_index': 0.10405519196090188, 'true_negative_rate': 0.6771134316481539, 'true_positive_rate': 0.8252933940623026, 'true_positive_rate_difference': 0.08186953122461305}\n",
            "-------------------------------------------------\n",
            "-------------------------------------------------\n",
            "Thank you for using this model. The Grid Training is now complete.\n",
            "-------------------------------------------------\n",
            "Now outputting the generated plots for the metrics of the latest trained model\n",
            "Model: ['Metafair']\n",
            "Trained on Year: ['2014'] Dataset ['rural'] Threshold: [50000]\n",
            "-------------------------------------------------\n",
            "[0, 1]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"1bde9b64-3fb0-4afc-84e1-7a15ec8d1ba3\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1bde9b64-3fb0-4afc-84e1-7a15ec8d1ba3\")) {                    Plotly.newPlot(                        \"1bde9b64-3fb0-4afc-84e1-7a15ec8d1ba3\",                        [{\"coloraxis\":\"coloraxis\",\"customdata\":[[0.7188710621852676,[\"rural\"],[0.7188710621852676]],[0.7188710621852676,[\"rural\"],[0.7188710621852676]],[0.7188710621852676,[\"rural\"],[0.7188710621852676]],[0.7188710621852676,[\"rural\"],[0.7188710621852676]],[0.7188710621852676,[\"rural\"],[0.7188710621852676]],[0.7188710621852676,[\"rural\"],[0.7188710621852676]],[0.7188710621852676,[\"rural\"],[0.7188710621852676]],[0.7188710621852676,[\"rural\"],[0.7188710621852676]],[0.7188710621852676,[\"rural\"],[0.7188710621852676]],[0.7188710621852676,[\"rural\"],[0.7188710621852676]],[0.7188710621852676,[\"rural\"],[0.7188710621852676]],[0.7188710621852676,[\"rural\"],[0.7188710621852676]],[0.7188710621852676,[\"rural\"],[0.7188710621852676]],[0.7188710621852676,[\"rural\"],[0.7188710621852676]],[0.7188710621852676,[\"rural\"],[0.7188710621852676]],[0.7188710621852676,[\"rural\"],[0.7188710621852676]],[0.7188710621852676,[\"rural\"],[0.7188710621852676]],[0.7188710621852676,[\"rural\"],[0.7188710621852676]],[0.7188710621852676,[\"rural\"],[0.7188710621852676]],[0.7188710621852676,[\"rural\"],[0.7188710621852676]],[0.7188710621852676,[\"rural\"],[0.7188710621852676]],[0.7188710621852676,[\"rural\"],[0.7188710621852676]],[0.7188710621852676,[\"rural\"],[0.7188710621852676]],[0.7188710621852676,[\"rural\"],[0.7188710621852676]],[0.7188710621852676,[\"rural\"],[0.7188710621852676]],[0.7188710621852676,[\"rural\"],[0.7188710621852676]],[0.7188710621852676,[\"rural\"],[0.7188710621852676]],[0.7188710621852676,[\"rural\"],[0.7188710621852676]],[0.7188710621852676,[\"rural\"],[0.7188710621852676]],[0.7188710621852676,[\"rural\"],[0.7188710621852676]],[0.7188710621852676,[\"rural\"],[0.7188710621852676]],[0.7188710621852676,[\"rural\"],[0.7188710621852676]]],\"geo\":\"geo\",\"hovertemplate\":\"state_code=%{location}<br>mean value=%{z}<br>regions=%{customdata[1]}<br>values=%{customdata[2]}<extra></extra>\",\"locationmode\":\"USA-states\",\"locations\":[\"PA\",\"OH\",\"NM\",\"VA\",\"GA\",\"MI\",\"KS\",\"MN\",\"LA\",\"NE\",\"IN\",\"ID\",\"MO\",\"WI\",\"TN\",\"SC\",\"OK\",\"NC\",\"AK\",\"WY\",\"IA\",\"NH\",\"ND\",\"AL\",\"KY\",\"SD\",\"AR\",\"MT\",\"MS\",\"WV\",\"VT\",\"ME\"],\"name\":\"\",\"z\":[0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676],\"type\":\"choropleth\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"geo\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"center\":{},\"scope\":\"usa\"},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"mean value\"}},\"colorscale\":[[0.0,\"rgb(3, 35, 51)\"],[0.09090909090909091,\"rgb(13, 48, 100)\"],[0.18181818181818182,\"rgb(53, 50, 155)\"],[0.2727272727272727,\"rgb(93, 62, 153)\"],[0.36363636363636365,\"rgb(126, 77, 143)\"],[0.45454545454545453,\"rgb(158, 89, 135)\"],[0.5454545454545454,\"rgb(193, 100, 121)\"],[0.6363636363636364,\"rgb(225, 113, 97)\"],[0.7272727272727273,\"rgb(246, 139, 69)\"],[0.8181818181818182,\"rgb(251, 173, 60)\"],[0.9090909090909091,\"rgb(246, 211, 70)\"],[1.0,\"rgb(231, 250, 90)\"]],\"cmin\":0,\"cmax\":1,\"showscale\":true},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"all selected data sets (mean values)\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1bde9b64-3fb0-4afc-84e1-7a15ec8d1ba3');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"186db138-590b-4411-bccb-45d4f11bfe3e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"186db138-590b-4411-bccb-45d4f11bfe3e\")) {                    Plotly.newPlot(                        \"186db138-590b-4411-bccb-45d4f11bfe3e\",                        [{\"coloraxis\":\"coloraxis\",\"customdata\":[[0.7188710621852676,\"rural\"],[0.7188710621852676,\"rural\"],[0.7188710621852676,\"rural\"],[0.7188710621852676,\"rural\"],[0.7188710621852676,\"rural\"],[0.7188710621852676,\"rural\"],[0.7188710621852676,\"rural\"],[0.7188710621852676,\"rural\"],[0.7188710621852676,\"rural\"],[0.7188710621852676,\"rural\"],[0.7188710621852676,\"rural\"],[0.7188710621852676,\"rural\"],[0.7188710621852676,\"rural\"],[0.7188710621852676,\"rural\"],[0.7188710621852676,\"rural\"],[0.7188710621852676,\"rural\"],[0.7188710621852676,\"rural\"],[0.7188710621852676,\"rural\"],[0.7188710621852676,\"rural\"],[0.7188710621852676,\"rural\"],[0.7188710621852676,\"rural\"],[0.7188710621852676,\"rural\"],[0.7188710621852676,\"rural\"],[0.7188710621852676,\"rural\"],[0.7188710621852676,\"rural\"],[0.7188710621852676,\"rural\"],[0.7188710621852676,\"rural\"],[0.7188710621852676,\"rural\"],[0.7188710621852676,\"rural\"],[0.7188710621852676,\"rural\"],[0.7188710621852676,\"rural\"],[0.7188710621852676,\"rural\"]],\"geo\":\"geo\",\"hovertemplate\":\"state_code=%{location}<br>value=%{z}<br>regions=%{customdata[1]}<extra></extra>\",\"locationmode\":\"USA-states\",\"locations\":[\"PA\",\"OH\",\"NM\",\"VA\",\"GA\",\"MI\",\"KS\",\"MN\",\"LA\",\"NE\",\"IN\",\"ID\",\"MO\",\"WI\",\"TN\",\"SC\",\"OK\",\"NC\",\"AK\",\"WY\",\"IA\",\"NH\",\"ND\",\"AL\",\"KY\",\"SD\",\"AR\",\"MT\",\"MS\",\"WV\",\"VT\",\"ME\"],\"name\":\"\",\"z\":[0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676,0.7188710621852676],\"type\":\"choropleth\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"geo\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"center\":{},\"scope\":\"usa\"},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"value\"}},\"colorscale\":[[0.0,\"rgb(165,0,38)\"],[0.1,\"rgb(215,48,39)\"],[0.2,\"rgb(244,109,67)\"],[0.3,\"rgb(253,174,97)\"],[0.4,\"rgb(254,224,139)\"],[0.5,\"rgb(255,255,191)\"],[0.6,\"rgb(217,239,139)\"],[0.7,\"rgb(166,217,106)\"],[0.8,\"rgb(102,189,99)\"],[0.9,\"rgb(26,152,80)\"],[1.0,\"rgb(0,104,55)\"]],\"cmin\":0,\"cmax\":1},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"rural\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('186db138-590b-4411-bccb-45d4f11bfe3e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}